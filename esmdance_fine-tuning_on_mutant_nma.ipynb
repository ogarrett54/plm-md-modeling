{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcd499fb",
   "metadata": {},
   "source": [
    "# Fine-tune ESMDance on Custom NMA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9be961ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a079220",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FineTuneNMADataset(Dataset):\n",
    "    \"\"\"A dataset for fine-tuning on custom NMA features from .npz files.\"\"\"\n",
    "    def __init__(self, sequences, nma_features_paths):\n",
    "        self.sequences = sequences\n",
    "        self.nma_features_paths = nma_features_paths\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t12_35M_UR50D\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        sequence = self.sequences[idx]\n",
    "        tokenized_output = self.tokenizer(sequence, return_tensors='pt')\n",
    "        inputs = {key: val.squeeze(0) for key, val in tokenized_output.items()}\n",
    "\n",
    "        # Load NMA features\n",
    "        nma_data = np.load(self.nma_features_paths[idx])\n",
    "        gnm_msf = torch.from_numpy(nma_data['gnm_msf']).float()\n",
    "        anm_cor = torch.from_numpy(nma_data['anm_cor']).float()\n",
    "\n",
    "        labels = {\n",
    "            'nma_residue1': gnm_msf[0],\n",
    "            'nma_residue2': gnm_msf[1],\n",
    "            'nma_residue3': gnm_msf[2],\n",
    "            'nma_pair1': anm_cor[0],\n",
    "            'nma_pair2': anm_cor[1],\n",
    "            'nma_pair3': anm_cor[2]\n",
    "        }\n",
    "        \n",
    "        return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cddf0bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_nma(batch):\n",
    "    \"\"\"\n",
    "    Collator function to pad sequences and features at the batch level.\n",
    "    This version correctly pads all labels to match the tokenized input length.\n",
    "    \"\"\"\n",
    "    batch_inputs = [item[0] for item in batch]\n",
    "    batch_labels = [item[1] for item in batch]\n",
    "\n",
    "    # --- Pad Inputs (This part was always correct) ---\n",
    "    padded_inputs = {}\n",
    "    padded_inputs['input_ids'] = pad_sequence(\n",
    "        [b['input_ids'] for b in batch_inputs], batch_first=True, padding_value=1\n",
    "    )\n",
    "    padded_inputs['attention_mask'] = pad_sequence(\n",
    "        [b['attention_mask'] for b in batch_inputs], batch_first=True, padding_value=0\n",
    "    )\n",
    "    \n",
    "    # This is the target length for all tensors (e.g., 160)\n",
    "    max_len = padded_inputs['input_ids'].shape[1]\n",
    "\n",
    "    # --- Pad Labels (CORRECTED LOGIC) ---\n",
    "    padded_labels = {}\n",
    "    for key in batch_labels[0].keys():\n",
    "        if 'residue' in key:\n",
    "            # --- THIS IS THE FIX ---\n",
    "            padded_tensors = []\n",
    "            for b in batch_labels:\n",
    "                tensor = b[key]  # Shape: (num_residues,) e.g., (158,)\n",
    "                # Manually pad each residue tensor to the full token length (160)\n",
    "                num_padding = max_len - tensor.shape[0]\n",
    "                padded_tensor = torch.nn.functional.pad(tensor, (0, num_padding), value=-1)\n",
    "                padded_tensors.append(padded_tensor)\n",
    "            # Stack the now correctly-sized tensors\n",
    "            padded_labels[key] = torch.stack(padded_tensors)\n",
    "        \n",
    "        elif 'pair' in key:\n",
    "            # The pairwise padding logic was already correct\n",
    "            padded_tensors = []\n",
    "            for b in batch_labels:\n",
    "                tensor = b[key]\n",
    "                n = tensor.shape[0]\n",
    "                padded_tensor = torch.nn.functional.pad(tensor, (0, max_len - n, 0, max_len - n), value=-1)\n",
    "                padded_tensors.append(padded_tensor)\n",
    "            padded_labels[key] = torch.stack(padded_tensors)\n",
    "\n",
    "    return padded_inputs, padded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f603420d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nma/I48K.npz',\n",
       " 'nma/A64Y-V10G-S30N-G45V-S55I.npz',\n",
       " 'nma/D36F-S16F-V34S-L37V-K73C.npz',\n",
       " 'nma/S30P-G47I.npz',\n",
       " 'nma/Q4P-S55W-D39R.npz',\n",
       " 'nma/I41Y-K9M.npz',\n",
       " 'nma/S16Y.npz',\n",
       " 'nma/K60T-G35P-L21T-V69I.npz',\n",
       " 'nma/L37H-S30G.npz',\n",
       " 'nma/L67P.npz',\n",
       " 'nma/E42H-K9W.npz',\n",
       " 'nma/V7Q-K73V-G47K.npz',\n",
       " 'nma/D49N-K73Y-G35W-G1V.npz',\n",
       " 'nma/V69S-E65G-A64V-G45A.npz',\n",
       " 'nma/D36A-L67H-I41R-G62V.npz',\n",
       " 'nma/K9M-D29L-L33D-V31N.npz',\n",
       " 'nma/A72D-R38H-A18M-D39N-V44I.npz',\n",
       " 'nma/K5N-K3L-A72F.npz',\n",
       " 'nma/D49H-G47M-I8S-L67I-M12D.npz',\n",
       " 'nma/N13G-L66F-K74C-V61F.npz',\n",
       " 'nma/h1-C_rcsb_cut.relax.npz',\n",
       " 'nma/V10A-L57V-S24G.npz',\n",
       " 'nma/A18T-K3I-L66S-S30E-K73Q.npz',\n",
       " 'nma/D63F-C14V-S70F-L21G.npz',\n",
       " 'nma/N13L.npz',\n",
       " 'nma/K9S.npz',\n",
       " 'nma/A56H-L2W-C14N.npz',\n",
       " 'nma/K3H.npz',\n",
       " 'nma/D63I-L53N.npz',\n",
       " 'nma/L66A-E65P-R58K-A23V-G62K.npz',\n",
       " 'nma/L2S-V31D-S24K.npz',\n",
       " 'nma/V34M-V7A-Q4A-V69Y-A64P.npz',\n",
       " 'nma/V43E-P50N-S30W-Q68E-T25W.npz',\n",
       " 'nma/L21W-R58P-K52H-I48Y-V44C.npz',\n",
       " 'nma/M12G-G45F-L2D-L21P-V28M.npz',\n",
       " 'nma/M12E-K17G-L2W-A11T-V61R.npz',\n",
       " 'nma/D49H-L67V-G26T-I54K-V10K.npz',\n",
       " 'nma/V10R-S55Y-K5T-L67E-T25H.npz',\n",
       " 'nma/A11L-M19A-G1C-G26S-L57N.npz',\n",
       " 'nma/A20M-M19P-A32Y-I6L-A11C.npz',\n",
       " 'nma/K52W.npz',\n",
       " 'nma/V28A-I41P-R58W.npz',\n",
       " 'nma/I54H.npz',\n",
       " 'nma/I41Y-G45Y.npz',\n",
       " 'nma/V43I-L66C-K17D-G47H.npz',\n",
       " 'nma/I8V-V10R-K40V-V34Q.npz',\n",
       " 'nma/I54C-I48H-G45V-V31S-A64S.npz',\n",
       " 'nma/V7T-V22T-I51Y-A23R.npz',\n",
       " 'nma/T25Q-S16K-Q4H.npz',\n",
       " 'nma/L67P-A64V-I51R-L33H.npz',\n",
       " 'nma/S55W-V31E-R58P.npz',\n",
       " 'nma/L66C-K40Q-I51D-S70I.npz',\n",
       " 'nma/K73C.npz',\n",
       " 'nma/S70W-L37D-D29F-V34P.npz',\n",
       " 'nma/I51K-D49P-A11W-S55G-I54Q.npz',\n",
       " 'nma/V22I-L37F.npz',\n",
       " 'nma/K60A.npz',\n",
       " 'nma/A23W-K40H.npz',\n",
       " 'nma/Q68P-Q4K.npz',\n",
       " 'nma/N13I-L53W-K74P-A20D.npz',\n",
       " 'nma/G47M-V7K.npz',\n",
       " 'nma/G26R-K60A-K17T-K73C.npz',\n",
       " 'nma/A23R-I54F-V7W.npz',\n",
       " 'nma/G45V-A56C-P50I-K40C.npz',\n",
       " 'nma/S30E-K59E.npz',\n",
       " 'nma/L33E-G47T-L67P-E42W.npz',\n",
       " 'nma/A23R.npz',\n",
       " 'nma/R38Y-I8T-L67E-V44D.npz',\n",
       " 'nma/K17C-L21H.npz',\n",
       " 'nma/A20F.npz',\n",
       " 'nma/V28M-S30L.npz',\n",
       " 'nma/A56E-I6D.npz',\n",
       " 'nma/V43F-L21F.npz',\n",
       " 'nma/R15E-K40F-P50S.npz',\n",
       " 'nma/L37R.npz',\n",
       " 'nma/V22A-Q68E-K73M.npz',\n",
       " 'nma/K73D-V44Q-K59Y-V28K.npz',\n",
       " 'nma/D36Y.npz',\n",
       " 'nma/R15L-D36L-V7L-K17V-G62I.npz',\n",
       " 'nma/G62Y-V7W-M19Y-V31F-D49A.npz',\n",
       " 'nma/Q4P-L53W-S24L-G35K.npz',\n",
       " 'nma/T25Q-K17S-K3P.npz',\n",
       " 'nma/G45Y-A56I-L66Y-G35S.npz',\n",
       " 'nma/K73R-L33D-R38I-K17G.npz',\n",
       " 'nma/V7L-K5Y-E65Y-R58W.npz',\n",
       " 'nma/V44T-R38D.npz',\n",
       " 'nma/T25P-K74E.npz',\n",
       " 'nma/D36V-L67I-D49Y-M19S.npz',\n",
       " 'nma/V69T-K59S.npz',\n",
       " 'nma/I8C-K52V-G47V-S30V-A32Q.npz',\n",
       " 'nma/S55M-K60T-C14Y-A72N-V43T.npz',\n",
       " 'nma/R58H.npz',\n",
       " 'nma/Y46V-K74S-A18I.npz',\n",
       " 'nma/G35M-I54R-K5R.npz',\n",
       " 'nma/L66Y.npz',\n",
       " 'nma/V61P-P50K-I8P-D49E-S55M.npz',\n",
       " 'nma/K74S-C14P-P50V-V43R.npz',\n",
       " 'nma/L53A.npz',\n",
       " 'nma/N13V-R38I-K52Q-V61L.npz',\n",
       " 'nma/L33K-V28C-K5E-L37E-L53Y.npz',\n",
       " 'nma/I8P-L53E.npz',\n",
       " 'nma/D63Q.npz',\n",
       " 'nma/L21M-T25N-K52E.npz',\n",
       " 'nma/G35V-D63I-Q68L.npz',\n",
       " 'nma/N13K-L33N.npz',\n",
       " 'nma/A72D-G26H.npz',\n",
       " 'nma/G26K-C14Q-G27I-L67H.npz',\n",
       " 'nma/L57V-V43M.npz',\n",
       " 'nma/K17D-I8C-V22D-A72K-V7P.npz',\n",
       " 'nma/I48Q-G35H-V43P-A32V-D63K.npz',\n",
       " 'nma/K60N-A32D-D63C-Q4F.npz',\n",
       " 'nma/A18L-S30Y-D36R.npz',\n",
       " 'nma/K73R.npz',\n",
       " 'nma/L2E-K60M-V69N-G35W.npz',\n",
       " 'nma/Q68Y-A32N-A64S-E65W-V69D.npz',\n",
       " 'nma/V69I-Q68V-E42H-D49V-S24P.npz',\n",
       " 'nma/E42Q-A20V.npz',\n",
       " 'nma/V61Q-S30V-D39I-R58A-Q71Y.npz',\n",
       " 'nma/K17H-I6A-K74R-V10I-A72Q.npz',\n",
       " 'nma/V7S-S30A.npz',\n",
       " 'nma/K3Y-I51E-E65W.npz',\n",
       " 'nma/V69F-R15W.npz',\n",
       " 'nma/V10T-K3N-Q68A-G62N-S16C.npz',\n",
       " 'nma/E42R-L2G-K60V.npz',\n",
       " 'nma/A20L-A23K-A11G-G45T.npz',\n",
       " 'nma/V7A-R38S-I41M.npz',\n",
       " 'nma/R15C-A64H-K60Q-L67R.npz',\n",
       " 'nma/S55T-A20L-L66M-Y46N-V22K.npz',\n",
       " 'nma/D63C-L53I.npz',\n",
       " 'nma/L57P-K73I-V34H-V28T.npz',\n",
       " 'nma/Y46R-P50N.npz',\n",
       " 'nma/C14G.npz',\n",
       " 'nma/I54Y-V28G-V44A.npz',\n",
       " 'nma/M19Q-G62L-E42H.npz',\n",
       " 'nma/T25G-V43Y-K40Q.npz',\n",
       " 'nma/G27S-V22D-K74A.npz',\n",
       " 'nma/R15G.npz',\n",
       " 'nma/V22E-V61D-D29G-I54F.npz',\n",
       " 'nma/K60M-K9W.npz',\n",
       " 'nma/K40R-G26F-I8K-A64Y.npz',\n",
       " 'nma/K17V-V69E-V61Y-A56L-L21F.npz',\n",
       " 'nma/Q71H-I48E-V69K-A20R.npz',\n",
       " 'nma/M12L-K40Q-V69A-K5I-G47W.npz',\n",
       " 'nma/S24Q-G62N-T25C-V43W-K74R.npz',\n",
       " 'nma/M19G.npz',\n",
       " 'nma/S16A.npz',\n",
       " 'nma/L2C-V10S-I51F-A20I.npz',\n",
       " 'nma/S30H.npz',\n",
       " 'nma/A72D-A18K.npz',\n",
       " 'nma/D49Q-S30A-V7N.npz',\n",
       " 'nma/G26Q-R58H-Q71I-A72E-K60M.npz',\n",
       " 'nma/R58L-Q4C-R15I.npz',\n",
       " 'nma/V69F-Y46V-K3V-A23L-V28I.npz',\n",
       " 'nma/I8V.npz',\n",
       " 'nma/A11H-K52E-S24N-G45N.npz',\n",
       " 'nma/R58N.npz',\n",
       " 'nma/L33R-K9E.npz',\n",
       " 'nma/L57E-K5Y.npz',\n",
       " 'nma/V22G-V31T-N13G.npz',\n",
       " 'nma/I54F-V28K-A32H-R38N.npz',\n",
       " 'nma/A64W-S70Y-C14H-K74Q.npz',\n",
       " 'nma/A64L-G62Y-K9M.npz',\n",
       " 'nma/D39M-L37N.npz',\n",
       " 'nma/A72F-K74S-D36W-A11P-G27Q.npz',\n",
       " 'nma/G62E-D63N-A11E-T25C.npz',\n",
       " 'nma/A20F-A32E.npz',\n",
       " 'nma/E65W.npz',\n",
       " 'nma/A23Y-E42P-V7S.npz',\n",
       " 'nma/K9A-D49L-R15N-K74F-V28S.npz',\n",
       " 'nma/G47I-G27P-I54W.npz',\n",
       " 'nma/R15C.npz',\n",
       " 'nma/K40M.npz',\n",
       " 'nma/L37K.npz',\n",
       " 'nma/I48G-L53H.npz',\n",
       " 'nma/G26R-M19H-D49K.npz',\n",
       " 'nma/S16G-T25F.npz',\n",
       " 'nma/Q68P-D36C-L53C.npz',\n",
       " 'nma/I54P-V10Y-G45E-V28Y-P50G.npz',\n",
       " 'nma/A11K-M19V-D63S-L33F-K59S.npz',\n",
       " 'nma/K59R-K9V-K17Y.npz',\n",
       " 'nma/N13Q-S16K.npz',\n",
       " 'nma/V61W-D29I.npz',\n",
       " 'nma/Y46M.npz',\n",
       " 'nma/I54R-D36K.npz',\n",
       " 'nma/D63R.npz',\n",
       " 'nma/M19P-V22C.npz',\n",
       " 'nma/V43Y.npz',\n",
       " 'nma/Q71W.npz',\n",
       " 'nma/V28C-I51M-A64Y-Q4C-S30W.npz',\n",
       " 'nma/A23H-L53H-A64R-R15G-K74L.npz',\n",
       " 'nma/K52F.npz',\n",
       " 'nma/A18M-G35A-Y46R.npz',\n",
       " 'nma/D29V-K5C-A64Y-S16Q.npz',\n",
       " 'nma/K52I-K73F-V7H.npz',\n",
       " 'nma/R58L-V34D-I6V.npz',\n",
       " 'nma/A32R-I41M-C14N-K40V.npz',\n",
       " 'nma/S55T-I51G-G27N-K40A.npz',\n",
       " 'nma/L57C-D39L-T25S-Q68P.npz',\n",
       " 'nma/V61Y-A23G-V44G-V22N-Q4T.npz',\n",
       " 'nma/S55C-K59A-P50K.npz',\n",
       " 'nma/Q4G.npz',\n",
       " 'nma/G26E-V43K-K60Q-V34G-L66C.npz',\n",
       " 'nma/V7P-P50Q-G62V-V44Q.npz',\n",
       " 'nma/G62P-I41Q-D49C.npz',\n",
       " 'nma/R38P-L33Q-V61M.npz',\n",
       " 'nma/P50F-A11W-S55F-S16T-K9C.npz',\n",
       " 'nma/D36Q.npz',\n",
       " 'nma/M12A-E65N-G27A-V69S.npz',\n",
       " 'nma/I48T-K40W-E65I.npz',\n",
       " 'nma/L57K-S16D-S30L-V61T-K60G.npz',\n",
       " 'nma/I51C-Q68C-V22A-D39L.npz',\n",
       " 'nma/V7F-R15G-K52N-N13K-V10E.npz',\n",
       " 'nma/C14G-V7R-L33I-V43R.npz',\n",
       " 'nma/K59E-K52V-L67D-Q68P.npz',\n",
       " 'nma/A72D-L53W-I54D-K59H-S30R.npz',\n",
       " 'nma/K9W-S16P-K3D-V10P-L66M.npz',\n",
       " 'nma/E65T-C14N-D36Q-L2V-L21W.npz',\n",
       " 'nma/Q71S-D63A-R15D.npz',\n",
       " 'nma/M12E-I48A-S55T-K60L-L67M.npz',\n",
       " 'nma/Q71R.npz',\n",
       " 'nma/G27F-A20C-L67N-V34D-L53N.npz',\n",
       " 'nma/G1H-T25I-S24C-K5A-V69R.npz',\n",
       " 'nma/K9P-R15S-K40V.npz',\n",
       " 'nma/I6W-G26M-L33Y.npz',\n",
       " 'nma/Y46F-L33Q-I48L-S16F-V28H.npz',\n",
       " 'nma/Q68A-G45D-I6F-L57Q-G35R.npz',\n",
       " 'nma/L21K-N13E-A56H-A18R-K74W.npz',\n",
       " 'nma/S70G-E65R-K52R-G35S.npz',\n",
       " 'nma/K73F-D63K.npz',\n",
       " 'nma/M12L-A20C-A23P.npz',\n",
       " 'nma/G27A-V31S.npz',\n",
       " 'nma/D29T-G35E-V69H.npz',\n",
       " 'nma/I51H-A11D-D29T-N13Q.npz',\n",
       " 'nma/V28G-L33Y.npz',\n",
       " 'nma/Q68A.npz',\n",
       " 'nma/Q4L.npz',\n",
       " 'nma/V44S-I41E-K73L-G1Q-A64E.npz',\n",
       " 'nma/V43F-V44D-G47W-L57M-E42D.npz',\n",
       " 'nma/V61E-S16L.npz',\n",
       " 'nma/V69R-R58W-I6V-E42K-L37D.npz',\n",
       " 'nma/I6R-R15V-A32P.npz',\n",
       " 'nma/R38L.npz',\n",
       " 'nma/Q71L-I51R-M12R-K3S-L37E.npz',\n",
       " 'nma/I48D-Q4D.npz',\n",
       " 'nma/G45R-K9H-K5I-I48E-L2D.npz',\n",
       " 'nma/K74N-Q71I-K3C-K17Q-G35A.npz',\n",
       " 'nma/Q71I-K9D-S16T-V28W-A56G.npz',\n",
       " 'nma/K73E.npz',\n",
       " 'nma/R58C.npz',\n",
       " 'nma/K3L-S24F.npz',\n",
       " 'nma/L67W.npz',\n",
       " 'nma/G45V-Q4G.npz',\n",
       " 'nma/D63T.npz',\n",
       " 'nma/L2C-S24N-V7G-M12D.npz',\n",
       " 'nma/K60F-V7H-C14Y.npz',\n",
       " 'nma/E42I-G26Q.npz',\n",
       " 'nma/L21N-E65T-K60S-P50A-A20E.npz',\n",
       " 'nma/A20D.npz',\n",
       " 'nma/Q68W.npz',\n",
       " 'nma/Q4P-K73V-I54V-Q71A-K59C.npz',\n",
       " 'nma/M19I.npz',\n",
       " 'nma/K9M.npz',\n",
       " 'nma/K52S-D39R.npz',\n",
       " 'nma/K73P-K5W-L33P.npz',\n",
       " 'nma/A20K-E42A.npz',\n",
       " 'nma/I54S-S24T-V28T-A32T-K73C.npz',\n",
       " 'nma/V28Q.npz',\n",
       " 'nma/A20G.npz',\n",
       " 'nma/T25A-S70K-A20K.npz',\n",
       " 'nma/C14P-I6H-M19A-I8V-I51R.npz',\n",
       " 'nma/L37S-R15Y-D36H-A11M.npz',\n",
       " 'nma/L33W.npz',\n",
       " 'nma/A18W-T25F-D49M.npz',\n",
       " 'nma/I8S.npz',\n",
       " 'nma/V44Y.npz',\n",
       " 'nma/G27F-L67T.npz',\n",
       " 'nma/G45T-G47W-T25V.npz',\n",
       " 'nma/D49R-R38T-I6W-V34S-S24V.npz',\n",
       " 'nma/L37T-I54C-R15A-Q4Y-R38K.npz',\n",
       " 'nma/K3N-V7G.npz',\n",
       " 'nma/G1N-K17T-A32Y-V44N-V10I.npz',\n",
       " 'nma/D29F.npz',\n",
       " 'nma/T25W.npz',\n",
       " 'nma/I8S-A56C-A20V-K74C.npz',\n",
       " 'nma/A18M-A20N-A56E-P50L.npz',\n",
       " 'nma/V7A-L21P-A32H.npz',\n",
       " 'nma/V69K-A11K-G62C-R58T-V7L.npz',\n",
       " 'nma/Y46G-V44T-A32L-S30Y-K3H.npz',\n",
       " 'nma/I51R-E42H.npz',\n",
       " 'nma/K40G-D36C-I41T-K74Y-M19H.npz',\n",
       " 'nma/K74C-A64H-G1S-V7M-V34R.npz',\n",
       " 'nma/A72E-Q71S-L2G.npz',\n",
       " 'nma/E65I-S55W-A56P-S24Q-Q4M.npz',\n",
       " 'nma/L37N-I48M-I6V.npz',\n",
       " 'nma/A20W-A18P-V69D-L67R.npz',\n",
       " 'nma/G47S-V7S-L21T-K74E.npz',\n",
       " 'nma/L67Y-S30P-G45F-V69E.npz',\n",
       " 'nma/L33M-K3V.npz',\n",
       " 'nma/V28M-V7M-I6L-A32R.npz',\n",
       " 'nma/V61Y-C14W-S24G-K3R.npz']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mut_df = pd.read_csv('mutant_library/h1-c_relaxed/mutant_library.csv')\n",
    "sequences = mut_df['sequence'].tolist()\n",
    "nma_paths = [f\"nma/{mut_string}.npz\" for mut_string in mut_df['mut']]\n",
    "\n",
    "nma_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "644d6f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # This section defines where your fine-tuned model and logs will be saved.\n",
    "    \"file_path\": {\n",
    "        \"save_dir\": \"models/esmdance-mutant-nma-fine-tuned_relaxed/\", \n",
    "    },\n",
    "    \n",
    "    # General training settings.\n",
    "    \"training\": {\n",
    "        \"random_seed\": 42,\n",
    "        \"dropout\": 0.1,\n",
    "        \n",
    "        # You should adjust these based on how often you want to save and log.\n",
    "        # For a shorter fine-tuning run, you'll want to save more frequently.\n",
    "        \"save_per_epoch\": 1, # It's easier to think in epochs for fine-tuning.\n",
    "        \n",
    "        # --- Feature Indices ---\n",
    "        \"res_feature_idx\": {\n",
    "            'nma_residue1': [0],\n",
    "            'nma_residue2': [1],\n",
    "            'nma_residue3': [2],\n",
    "        },\n",
    "        \"pair_feature_idx\": {\n",
    "            'nma_pair1': [0],\n",
    "            'nma_pair2': [1],\n",
    "            'nma_pair3': [2],\n",
    "        },\n",
    "    },\n",
    "\n",
    "    \"esmdance\": {\n",
    "        \"freeze_esm\": True,      # Correct for ESMDance fine-tuning.\n",
    "        \"randomize_esm\": False,\n",
    "        \n",
    "        # All your sequences are 158, so we set one max_len.\n",
    "        # We add a little buffer, but it could be exactly 158.\n",
    "        \"max_len\": 256,\n",
    "        \n",
    "        # Define training by epochs, which is more intuitive for a fixed dataset.\n",
    "        \"num_epochs\": 20, # Adjust this based on how your loss behaves.\n",
    "        \n",
    "        # Set a single batch size. Adjust based on your GPU memory.\n",
    "        \"batch_size\": 4,\n",
    "        \n",
    "        # Gradient accumulation helps simulate a larger batch size.\n",
    "        # Effective batch size = batch_size * gradient_accumulation_steps\n",
    "        # Example: 8 * 4 = 32\n",
    "        \"gradient_accumulation_steps\": 4, \n",
    "    },\n",
    "\n",
    "    # Optimizer settings. These are generally good starting points.\n",
    "    \"optimizer\": {\n",
    "        \"peak_lr\": 1e-4,\n",
    "        \"epsilon\": 1e-8,\n",
    "        \"betas\": (0.9, 0.98),\n",
    "        \"weight_decay\": 0.01,\n",
    "        \"warmup_steps\": 200, # Number of steps for learning rate warmup.\n",
    "    },\n",
    "\n",
    "    # --- CRITICAL CHANGE 3: Model Output Dimensions ---\n",
    "    \"model_35M\": {\n",
    "        \"model_id\": \"facebook/esm2_t12_35M_UR50D\",\n",
    "        \"atten_dim\": 240,\n",
    "        \"embed_dim\": 480,\n",
    "        \n",
    "        # These now match your NMA-only data.\n",
    "        \"pair_out_dim\": 3, # Was 13. Now 3 for your 3 ANM correlation matrices.\n",
    "        \"res_out_dim\": 3,  # Was 50. Now 3 for your 3 GNM fluctuation vectors.\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ba844a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "full_dataset = FineTuneNMADataset(sequences, nma_paths)\n",
    "\n",
    "# Split data into training and validation sets (e.g., 90% train, 10% val)\n",
    "train_size = int(0.9 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=config['esmdance']['batch_size'], \n",
    "    shuffle=True, \n",
    "    collate_fn=collate_fn_nma\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config['esmdance']['batch_size'],\n",
    "    shuffle=False, # No need to shuffle validation data\n",
    "    collate_fn=collate_fn_nma\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09bcb66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import EsmModel\n",
    "from huggingface_hub import PyTorchModelHubMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ba370d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESMwrap(nn.Module, PyTorchModelHubMixin):\n",
    "    def __init__(self, esm2_select, model_select):\n",
    "        super().__init__()\n",
    "        # Load the ESM2 model\n",
    "        self.esm2 = EsmModel.from_pretrained(config[esm2_select]['model_id'])\n",
    "        self.freeze_esm = config[model_select]['freeze_esm']\n",
    "\n",
    "        # Freeze self.esm2 parameters if freeze_esm is True\n",
    "        if self.freeze_esm:\n",
    "            for param in self.esm2.parameters():\n",
    "                param.requires_grad = False\n",
    "            self.esm2.eval()  # Set to evaluation mode\n",
    "\n",
    "        # Randomize self.esm2 parameters if randomize_esm is True\n",
    "        if config[model_select]['randomize_esm']:\n",
    "            self.randomize_model(self.esm2)\n",
    "\n",
    "        # dimensions of input and output\n",
    "        embed_dim = config[esm2_select]['embed_dim']\n",
    "        res_out_dim = config[esm2_select]['res_out_dim']\n",
    "        atten_dim = config[esm2_select]['atten_dim']\n",
    "        pair_out_dim = config[esm2_select]['pair_out_dim']\n",
    "\n",
    "        # Residue-level prediction layer\n",
    "        self.res_pred_nn = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm(embed_dim),\n",
    "            nn.Dropout(config['training']['dropout']),  # Apply dropout after LayerNorm\n",
    "            nn.Linear(embed_dim, res_out_dim)\n",
    "        )\n",
    "\n",
    "        # transform res embedding for Pairwise prediction\n",
    "        self.res_transform_nn = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm(embed_dim),\n",
    "            nn.Dropout(config['training']['dropout']),  # Apply dropout after LayerNorm\n",
    "            nn.Linear(embed_dim, embed_dim*2)\n",
    "        )\n",
    "\n",
    "        # Pairwise prediction layer\n",
    "        self.pair_middle_linear = nn.Linear(embed_dim*2, atten_dim)\n",
    "        self.pair_pred_linear = nn.Linear(atten_dim + atten_dim, pair_out_dim)\n",
    "\n",
    "        # Activation functions\n",
    "        self.gelu = nn.GELU()\n",
    "        self.softplus = nn.Softplus(beta=1.0, threshold=2.0)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "        # Feature indices from config\n",
    "        self.res_feature_idx = config['training']['res_feature_idx']\n",
    "        self.pair_feature_idx = config['training']['pair_feature_idx']\n",
    "\n",
    "        # Initialize biases to zero\n",
    "        self._init_bias_zero()\n",
    "\n",
    "    def randomize_model(self, model):\n",
    "        \"\"\" Randomize the parameters of the given model. \"\"\"\n",
    "        for module_ in model.named_modules():\n",
    "            if isinstance(module_[1], (torch.nn.Linear, torch.nn.Embedding)):\n",
    "                if hasattr(module_[1], 'bias') and module_[1].bias is not None:\n",
    "                    module_[1].bias.data.zero_()\n",
    "                if hasattr(module_[1], 'weight'):\n",
    "                    if 'query' in module_[0] or 'key' in module_[0] or 'value' in module_[0]:\n",
    "                        module_[1].weight = nn.init.xavier_uniform_(module_[1].weight, gain=1 / math.sqrt(2))\n",
    "                    else:\n",
    "                        module_[1].weight = nn.init.xavier_uniform_(module_[1].weight)\n",
    "                            \n",
    "            elif isinstance(module_[1], nn.LayerNorm):\n",
    "                if hasattr(module_[1], 'bias'):\n",
    "                    module_[1].bias.data.zero_()\n",
    "                if hasattr(module_[1], 'weight'):\n",
    "                    module_[1].weight.data.fill_(1.0)\n",
    "                \n",
    "            elif isinstance(module_[1], nn.Dropout):\n",
    "                module_[1].p = config['training']['dropout']\n",
    "\n",
    "\n",
    "    def _init_bias_zero(self):\n",
    "        \"\"\" Set all biases in the model (excluding esm2) to zero. \"\"\"\n",
    "        for name, module in self.named_modules():\n",
    "            if \"esm2\" not in name and isinstance(module, nn.Linear) and module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "\n",
    "\n",
    "    def forward(self, inputs, return_res_emb=False, return_attention_map=False, return_res_pred=True, return_pair_pred=True):\n",
    "        output = {}\n",
    "\n",
    "        # ESM forward pass, Ensure no gradients are stored for frozen ESM2\n",
    "        if self.freeze_esm:\n",
    "            with torch.no_grad():\n",
    "                esm_output = self.esm2(**inputs, output_attentions=True)\n",
    "        else:\n",
    "            esm_output = self.esm2(**inputs, output_attentions=True)\n",
    "\n",
    "        res_emb = esm_output['last_hidden_state']\n",
    "        pair_atten = torch.cat(esm_output['attentions'], dim=1).permute(0, 2, 3, 1)\n",
    "\n",
    "        if return_res_emb:\n",
    "            output['res_emb'] = res_emb\n",
    "        if return_attention_map:\n",
    "            output['attention_map'] = pair_atten\n",
    "\n",
    "        # Residue-level prediction\n",
    "        if return_res_pred:\n",
    "            res_pred = self.res_pred_nn(res_emb)\n",
    "            for feature in self.res_feature_idx:\n",
    "                if feature == 'rmsf_nor':\n",
    "                    # Normalized RMSF (max = 1)\n",
    "                    output[feature] = self.sigmoid(res_pred[:, :, self.res_feature_idx[feature]])\n",
    "                elif feature in ['ss', 'chi', 'phi', 'psi']:\n",
    "                    # Secondary structure, chi, phi, psi sum up to 1\n",
    "                    output[feature] = self.softmax(res_pred[:, :, self.res_feature_idx[feature]])\n",
    "                else:\n",
    "                    # All other features are non-negative\n",
    "                    output[feature] = self.softplus(res_pred[:, :, self.res_feature_idx[feature]])\n",
    "\n",
    "        # Pairwise transformation\n",
    "        s = self.res_transform_nn(res_emb)\n",
    "        q, k = s.chunk(2, dim=-1)\n",
    "        prod = q[:, None, :, :] * k[:, :, None, :]\n",
    "        diff = q[:, None, :, :] - k[:, :, None, :]\n",
    "        pair_middle = self.gelu(self.pair_middle_linear(torch.cat([prod, diff], dim=-1)))\n",
    "\n",
    "        # Pairwise prediction\n",
    "        if return_pair_pred:\n",
    "            pair_pred = self.pair_pred_linear(torch.cat([pair_middle, pair_atten], dim=-1))\n",
    "\n",
    "            for feature in self.pair_feature_idx:\n",
    "                if feature in ['corr', 'nma_pair1', 'nma_pair2', 'nma_pair3']:\n",
    "                    # Co-movement and NMA co-movement correlations: range [-1, 1]\n",
    "                    output[feature] = self.sigmoid(pair_pred[:, :, :, self.pair_feature_idx[feature]]) * 2 - 1.0\n",
    "                else:\n",
    "                    # All interaction features are non-negative\n",
    "                    output[feature] = self.softplus(pair_pred[:, :, :, self.pair_feature_idx[feature]])\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e73d2f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97759489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(config['training']['random_seed'])\n",
    "np.random.seed(config['training']['random_seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3132fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "# Create save directory from config\n",
    "save_dir = Path(config['file_path']['save_dir'])\n",
    "save_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "710ac295",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t12_35M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = ESMwrap(esm2_select='model_35M', model_select='esmdance').to(device)\n",
    "checkpoint = torch.load('pretrained_weights/esmdance_update_60000.pt')\n",
    "model_state_dict = model.state_dict()\n",
    "\n",
    "filtered_state_dict = {\n",
    "            k: v for k, v in checkpoint.items() \n",
    "            if k in model_state_dict and v.shape == model_state_dict[k].shape\n",
    "        }\n",
    "        \n",
    "# Update our new model's state dict with the filtered weights\n",
    "model_state_dict.update(filtered_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4841bbaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(model_state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0c9b501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===========================================================================================================================================================\n",
       "Layer (type (var_name))                                                     Input Shape          Output Shape         Param #              Trainable\n",
       "===========================================================================================================================================================\n",
       "ESMwrap (ESMwrap)                                                           [1, 160]             [1, 160, 160, 1]     --                   Partial\n",
       "├─EsmModel (esm2)                                                           --                   [1, 20, 160, 160]    241                  False\n",
       "│    └─EsmEmbeddings (embeddings)                                           --                   [1, 160, 480]        492,480              False\n",
       "│    │    └─Embedding (word_embeddings)                                     [1, 160]             [1, 160, 480]        (15,840)             False\n",
       "│    └─EsmEncoder (encoder)                                                 [1, 160, 480]        [1, 20, 160, 160]    --                   False\n",
       "│    │    └─ModuleList (layer)                                              --                   --                   (33,252,480)         False\n",
       "│    │    └─LayerNorm (emb_layer_norm_after)                                [1, 160, 480]        [1, 160, 480]        (960)                False\n",
       "│    └─EsmPooler (pooler)                                                   [1, 160, 480]        [1, 480]             --                   False\n",
       "│    │    └─Linear (dense)                                                  [1, 480]             [1, 480]             (230,880)            False\n",
       "│    │    └─Tanh (activation)                                               [1, 480]             [1, 480]             --                   --\n",
       "├─Sequential (res_pred_nn)                                                  [1, 160, 480]        [1, 160, 3]          --                   True\n",
       "│    └─Linear (0)                                                           [1, 160, 480]        [1, 160, 480]        230,880              True\n",
       "│    └─GELU (1)                                                             [1, 160, 480]        [1, 160, 480]        --                   --\n",
       "│    └─LayerNorm (2)                                                        [1, 160, 480]        [1, 160, 480]        960                  True\n",
       "│    └─Dropout (3)                                                          [1, 160, 480]        [1, 160, 480]        --                   --\n",
       "│    └─Linear (4)                                                           [1, 160, 480]        [1, 160, 3]          1,443                True\n",
       "├─Softplus (softplus)                                                       [1, 160, 1]          [1, 160, 1]          --                   --\n",
       "├─Softplus (softplus)                                                       [1, 160, 1]          [1, 160, 1]          --                   --\n",
       "├─Softplus (softplus)                                                       [1, 160, 1]          [1, 160, 1]          --                   --\n",
       "├─Sequential (res_transform_nn)                                             [1, 160, 480]        [1, 160, 960]        --                   True\n",
       "│    └─Linear (0)                                                           [1, 160, 480]        [1, 160, 480]        230,880              True\n",
       "│    └─GELU (1)                                                             [1, 160, 480]        [1, 160, 480]        --                   --\n",
       "│    └─LayerNorm (2)                                                        [1, 160, 480]        [1, 160, 480]        960                  True\n",
       "│    └─Dropout (3)                                                          [1, 160, 480]        [1, 160, 480]        --                   --\n",
       "│    └─Linear (4)                                                           [1, 160, 480]        [1, 160, 960]        461,760              True\n",
       "├─Linear (pair_middle_linear)                                               [1, 160, 160, 960]   [1, 160, 160, 240]   230,640              True\n",
       "├─GELU (gelu)                                                               [1, 160, 160, 240]   [1, 160, 160, 240]   --                   --\n",
       "├─Linear (pair_pred_linear)                                                 [1, 160, 160, 480]   [1, 160, 160, 3]     1,443                True\n",
       "├─Sigmoid (sigmoid)                                                         [1, 160, 160, 1]     [1, 160, 160, 1]     --                   --\n",
       "├─Sigmoid (sigmoid)                                                         [1, 160, 160, 1]     [1, 160, 160, 1]     --                   --\n",
       "├─Sigmoid (sigmoid)                                                         [1, 160, 160, 1]     [1, 160, 160, 1]     --                   --\n",
       "===========================================================================================================================================================\n",
       "Total params: 35,151,847\n",
       "Trainable params: 1,158,966\n",
       "Non-trainable params: 33,992,881\n",
       "Total mult-adds (Units.MEGABYTES): 34.66\n",
       "===========================================================================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 135.79\n",
       "Params size (MB): 138.64\n",
       "Estimated Total Size (MB): 274.43\n",
       "==========================================================================================================================================================="
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "batch_size = 1\n",
    "sequence_length = 160 # 158 residues + 2 special tokens\n",
    "\n",
    "dummy_input_ids = torch.randint(0, 33, (batch_size, sequence_length), dtype=torch.long)\n",
    "dummy_attention_mask = torch.ones(batch_size, sequence_length, dtype=torch.long)\n",
    "\n",
    "dummy_inputs_dict = {\n",
    "    \"input_ids\": dummy_input_ids,\n",
    "    \"attention_mask\": dummy_attention_mask\n",
    "}\n",
    "\n",
    "# This tells torchinfo to pass the dictionary as a single positional argument,\n",
    "# which matches your model's forward(self, inputs) signature.\n",
    "input_data_for_summary = (dummy_inputs_dict,)\n",
    "\n",
    "summary(\n",
    "    model,\n",
    "    # Pass the TUPLE containing the dictionary\n",
    "    input_data=input_data_for_summary,\n",
    "    \n",
    "    # The other summary arguments are for torchinfo itself and will no longer be passed to your model\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "    col_width=20,\n",
    "    row_settings=[\"var_names\"],\n",
    "    device=\"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "864bbd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 1,158,966\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.amp import GradScaler, autocast\n",
    "\n",
    "loss_function = nn.MSELoss(reduction='none') # Use reduction='none' for custom masking\n",
    "trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "print(f\"Total trainable parameters: {sum(p.numel() for p in trainable_params):,}\")\n",
    "optimizer = AdamW(trainable_params, lr=config['optimizer']['peak_lr'], betas=config['optimizer']['betas'])\n",
    "\n",
    "scaler = GradScaler() # For mixed-precision training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c66bc808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fine-tuning for 20 epochs...\n",
      "\n",
      "Epoch 1/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 14.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.0414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 22.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4743\n",
      "\n",
      "Epoch 2/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 23.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2665\n",
      "\n",
      "Epoch 3/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 [Training]: 100%|██████████| 68/68 [00:05<00:00, 13.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 16.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1996\n",
      "\n",
      "Epoch 4/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 [Training]: 100%|██████████| 68/68 [00:06<00:00, 10.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 21.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1612\n",
      "\n",
      "Epoch 5/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 21.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1314\n",
      "\n",
      "Epoch 6/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 [Training]: 100%|██████████| 68/68 [00:05<00:00, 13.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 20.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1079\n",
      "\n",
      "Epoch 7/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 [Training]: 100%|██████████| 68/68 [00:03<00:00, 21.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 23.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0899\n",
      "\n",
      "Epoch 8/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 13.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 21.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0761\n",
      "\n",
      "Epoch 9/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 14.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 21.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0657\n",
      "\n",
      "Epoch 10/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 14.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 23.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0577\n",
      "\n",
      "Epoch 11/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 14.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 24.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0511\n",
      "\n",
      "Epoch 12/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 14.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 23.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0460\n",
      "\n",
      "Epoch 13/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 [Training]: 100%|██████████| 68/68 [00:02<00:00, 23.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 23.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0417\n",
      "\n",
      "Epoch 14/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 14.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 21.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0378\n",
      "\n",
      "Epoch 15/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 14.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 24.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0350\n",
      "\n",
      "Epoch 16/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 14.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 22.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0322\n",
      "\n",
      "Epoch 17/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 14.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 23.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0298\n",
      "\n",
      "Epoch 18/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 14.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 22.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0279\n",
      "\n",
      "Epoch 19/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 14.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 24.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0266\n",
      "\n",
      "Epoch 20/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 [Training]: 100%|██████████| 68/68 [00:02<00:00, 24.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 23.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.amp import autocast\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = config['esmdance']['num_epochs']\n",
    "grad_accum_steps = config['esmdance']['gradient_accumulation_steps']\n",
    "\n",
    "print(f\"Starting fine-tuning for {num_epochs} epochs...\")\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'\\nEpoch {epoch+1}/{num_epochs}\\n------------------------------')\n",
    "    # =======================================\n",
    "    #               TRAINING\n",
    "    # =======================================\n",
    "    model.train() # Set the model to training mode\n",
    "    total_train_loss = 0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} [Training]\")):\n",
    "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "        labels = {key: val.to(device) for key, val in labels.items()}\n",
    "        \n",
    "        with autocast(device_type='cuda', dtype=torch.float16):\n",
    "            predictions = model(inputs)\n",
    "            \n",
    "            # --- Loss Calculation ---\n",
    "            res_loss = 0\n",
    "            res_mask = labels['nma_residue1'] != -1\n",
    "            for k in ['nma_residue1', 'nma_residue2', 'nma_residue3']:\n",
    "                pred_k = predictions[k].squeeze(-1)\n",
    "                label_k = labels[k]\n",
    "                element_wise_loss = loss_function(pred_k, label_k)\n",
    "                valid_losses = element_wise_loss[res_mask]\n",
    "                res_loss += valid_losses.mean()\n",
    "\n",
    "            pair_loss = 0\n",
    "            pair_mask = labels['nma_pair1'] != -1\n",
    "            for k in ['nma_pair1', 'nma_pair2', 'nma_pair3']:\n",
    "                pred_pair_k = predictions[k].squeeze(-1)\n",
    "                label_pair_k = labels[k]\n",
    "                element_wise_loss = loss_function(pred_pair_k, label_pair_k)\n",
    "                valid_losses = element_wise_loss[pair_mask]\n",
    "                pair_loss += valid_losses.mean()\n",
    "            \n",
    "            loss = (3 * pair_loss + res_loss) / grad_accum_steps\n",
    "        \n",
    "        # --- Gradient Accumulation & Backpropagation ---\n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        if (i + 1) % grad_accum_steps == 0 or (i + 1) == len(train_loader):\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        total_train_loss += loss.item() * grad_accum_steps\n",
    "        \n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    print(f\"Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # =======================================\n",
    "    #              VALIDATION\n",
    "    # =======================================\n",
    "    model.eval() # Set the model to evaluation mode\n",
    "    total_val_loss = 0\n",
    "    \n",
    "    # Disable gradient calculations for validation to save memory and compute\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} [Validation]\")):\n",
    "            inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "            labels = {key: val.to(device) for key, val in labels.items()}\n",
    "            \n",
    "            # Forward pass only, still use autocast for consistency\n",
    "            with autocast(device_type='cuda', dtype=torch.float16):\n",
    "                predictions = model(inputs)\n",
    "\n",
    "                # --- Loss Calculation (Identical to training) ---\n",
    "                res_loss = 0\n",
    "                res_mask = labels['nma_residue1'] != -1\n",
    "                for k in ['nma_residue1', 'nma_residue2', 'nma_residue3']:\n",
    "                    pred_k = predictions[k].squeeze(-1)\n",
    "                    label_k = labels[k]\n",
    "                    element_wise_loss = loss_function(pred_k, label_k)\n",
    "                    valid_losses = element_wise_loss[res_mask]\n",
    "                    res_loss += valid_losses.mean()\n",
    "\n",
    "                pair_loss = 0\n",
    "                pair_mask = labels['nma_pair1'] != -1\n",
    "                for k in ['nma_pair1', 'nma_pair2', 'nma_pair3']:\n",
    "                    pred_pair_k = predictions[k].squeeze(-1)\n",
    "                    label_pair_k = labels[k]\n",
    "                    element_wise_loss = loss_function(pred_pair_k, label_pair_k)\n",
    "                    valid_losses = element_wise_loss[pair_mask]\n",
    "                    pair_loss += valid_losses.mean()\n",
    "                \n",
    "                # Note: We do NOT divide by grad_accum_steps for validation loss\n",
    "                val_loss = 3 * pair_loss + res_loss\n",
    "            \n",
    "            total_val_loss += val_loss.item()\n",
    "            \n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4802d3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = save_dir / \"esmdance_fine-tuned_with_nma_data.pth\"\n",
    "torch.save(model.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cb0766",
   "metadata": {},
   "source": [
    "Validation loss after 20 epochs, no relax: 0.0219\n",
    "Validation loss after 20 epochs, with relax: 0.0247"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
