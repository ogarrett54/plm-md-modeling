{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcd499fb",
   "metadata": {},
   "source": [
    "# Fine-tune ESMDance on Custom NMA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9be961ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a079220",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FineTuneNMADataset(Dataset):\n",
    "    \"\"\"A dataset for fine-tuning on custom NMA features from .npz files.\"\"\"\n",
    "    def __init__(self, sequences, nma_features_paths):\n",
    "        self.sequences = sequences\n",
    "        self.nma_features_paths = nma_features_paths\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t12_35M_UR50D\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        sequence = self.sequences[idx]\n",
    "        tokenized_output = self.tokenizer(sequence, return_tensors='pt')\n",
    "        inputs = {key: val.squeeze(0) for key, val in tokenized_output.items()}\n",
    "\n",
    "        # Load NMA features\n",
    "        nma_data = np.load(self.nma_features_paths[idx])\n",
    "        gnm_msf = torch.from_numpy(nma_data['gnm_msf']).float()\n",
    "        anm_cor = torch.from_numpy(nma_data['anm_cor']).float()\n",
    "\n",
    "        labels = {\n",
    "            'nma_residue1': gnm_msf[0],\n",
    "            'nma_residue2': gnm_msf[1],\n",
    "            'nma_residue3': gnm_msf[2],\n",
    "            'nma_pair1': anm_cor[0],\n",
    "            'nma_pair2': anm_cor[1],\n",
    "            'nma_pair3': anm_cor[2]\n",
    "        }\n",
    "        \n",
    "        return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cddf0bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_nma(batch):\n",
    "    \"\"\"\n",
    "    Collator function to pad sequences and features at the batch level.\n",
    "    This version correctly pads all labels to match the tokenized input length.\n",
    "    \"\"\"\n",
    "    batch_inputs = [item[0] for item in batch]\n",
    "    batch_labels = [item[1] for item in batch]\n",
    "\n",
    "    # --- Pad Inputs (This part was always correct) ---\n",
    "    padded_inputs = {}\n",
    "    padded_inputs['input_ids'] = pad_sequence(\n",
    "        [b['input_ids'] for b in batch_inputs], batch_first=True, padding_value=1\n",
    "    )\n",
    "    padded_inputs['attention_mask'] = pad_sequence(\n",
    "        [b['attention_mask'] for b in batch_inputs], batch_first=True, padding_value=0\n",
    "    )\n",
    "    \n",
    "    # This is the target length for all tensors (e.g., 160)\n",
    "    max_len = padded_inputs['input_ids'].shape[1]\n",
    "\n",
    "    # --- Pad Labels (CORRECTED LOGIC) ---\n",
    "    padded_labels = {}\n",
    "    for key in batch_labels[0].keys():\n",
    "        if 'residue' in key:\n",
    "            # --- THIS IS THE FIX ---\n",
    "            padded_tensors = []\n",
    "            for b in batch_labels:\n",
    "                tensor = b[key]  # Shape: (num_residues,) e.g., (158,)\n",
    "                # Manually pad each residue tensor to the full token length (160)\n",
    "                num_padding = max_len - tensor.shape[0]\n",
    "                padded_tensor = torch.nn.functional.pad(tensor, (0, num_padding), value=-1)\n",
    "                padded_tensors.append(padded_tensor)\n",
    "            # Stack the now correctly-sized tensors\n",
    "            padded_labels[key] = torch.stack(padded_tensors)\n",
    "        \n",
    "        elif 'pair' in key:\n",
    "            # The pairwise padding logic was already correct\n",
    "            padded_tensors = []\n",
    "            for b in batch_labels:\n",
    "                tensor = b[key]\n",
    "                n = tensor.shape[0]\n",
    "                padded_tensor = torch.nn.functional.pad(tensor, (0, max_len - n, 0, max_len - n), value=-1)\n",
    "                padded_tensors.append(padded_tensor)\n",
    "            padded_labels[key] = torch.stack(padded_tensors)\n",
    "\n",
    "    return padded_inputs, padded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f603420d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nma/K105R-D136E.npz',\n",
       " 'nma/N87F-M121F-F102D-D136W.npz',\n",
       " 'nma/I149M-E83H-P127Q.npz',\n",
       " 'nma/K154D-M103H.npz',\n",
       " 'nma/D122F-D93A-N139C-P146V-G157H.npz',\n",
       " 'nma/V130R-G157T-N106H-G142V-N87C.npz',\n",
       " 'nma/G147T-I78F.npz',\n",
       " 'nma/I94Y-W101A-K124C-K133D-P145R.npz',\n",
       " 'nma/F100C-K120A-D135A-G157W-N107I.npz',\n",
       " 'nma/N139T-I132W-F88P.npz',\n",
       " 'nma/R155G-F104M-V108R-K124A.npz',\n",
       " 'nma/K133M-D111P-F102V.npz',\n",
       " 'nma/G142P-M121G-D111F.npz',\n",
       " 'nma/F89R-P156W.npz',\n",
       " 'nma/W101S-K153F.npz',\n",
       " 'nma/D135E-D85C-L151K-P156R.npz',\n",
       " 'nma/P97R-F158W.npz',\n",
       " 'nma/V130I-L140W-R109C-N106A-G152C.npz',\n",
       " 'nma/K153L-S117W.npz',\n",
       " 'nma/S117H-I78Q-A112R-P95K.npz',\n",
       " 'nma/P145D.npz',\n",
       " 'nma/G113Y.npz',\n",
       " 'nma/N106R-V150R-I94N-F88W-Y116H.npz',\n",
       " 'nma/I149G.npz',\n",
       " 'nma/M121D-N87S.npz',\n",
       " 'nma/N128T.npz',\n",
       " 'nma/W148P-K124D-V108N-L140Q.npz',\n",
       " 'nma/L80T-R82P.npz',\n",
       " 'nma/D136F-F88I-V125F-N139C.npz',\n",
       " 'nma/R84M-C99P-L140N-W101R.npz',\n",
       " 'nma/G126C.npz',\n",
       " 'nma/G113A-I132E-H131A-W119F.npz',\n",
       " 'nma/N128Y-D136K-V125C-N106Y.npz',\n",
       " 'nma/D111T-G142K-R82P.npz',\n",
       " 'nma/K154V-P86G-F104C-E98L-W148L.npz',\n",
       " 'nma/S117D-V125S-Y116F-C138K-K154A.npz',\n",
       " 'nma/D79G-E98I-D135N-K153H.npz',\n",
       " 'nma/P156R-I94K.npz',\n",
       " 'nma/M121D-P95M-K120H-F89S.npz',\n",
       " 'nma/R84W-S141R-L151D-M123G-C138Q.npz',\n",
       " 'nma/W101S-N87P-R155A-K120F-V108M.npz',\n",
       " 'nma/C99F-D93Q-W101S-F89Q-K124M.npz',\n",
       " 'nma/R109H-L80A-S134P-E98C-L140F.npz',\n",
       " 'nma/P127T-P95H-P86Y.npz',\n",
       " 'nma/K153D-R84P-K120G-F158Y-I149F.npz',\n",
       " 'nma/L140N.npz',\n",
       " 'nma/M103T-D90Q.npz',\n",
       " 'nma/D85S.npz',\n",
       " 'nma/W101H-C115Y-W119Q-Q110F.npz',\n",
       " 'nma/E83T-R155G.npz',\n",
       " 'nma/A92E-C138H-W129Y-Q110C.npz',\n",
       " 'nma/K153M-I149L-D93L.npz',\n",
       " 'nma/K120I-D93L-I78A.npz',\n",
       " 'nma/F104L.npz',\n",
       " 'nma/W129E-A112W.npz',\n",
       " 'nma/P145D-V150C-K105P-N128L-I78A.npz',\n",
       " 'nma/I78E-V108L-A112P-S134T-S141A.npz',\n",
       " 'nma/M103H-K133L-R109W.npz',\n",
       " 'nma/P97K-W148N-N137Q.npz',\n",
       " 'nma/D122Q.npz',\n",
       " 'nma/D122S-W148C.npz',\n",
       " 'nma/N91L-D135W.npz',\n",
       " 'nma/P95W-I94N-V130Y-I149S.npz',\n",
       " 'nma/F104P-P97M-D136E-E83P-N139F.npz',\n",
       " 'nma/P146Q-I78E-V108T-G152M.npz',\n",
       " 'nma/S134P-V130C-S118G.npz',\n",
       " 'nma/W129H.npz',\n",
       " 'nma/S134Y-G152D.npz',\n",
       " 'nma/G147V.npz',\n",
       " 'nma/F88T-N128A-W148M.npz',\n",
       " 'nma/P86C.npz',\n",
       " 'nma/W119R-P97V-S141G-E83H-M103W.npz',\n",
       " 'nma/N128W-D136T-R82H-K120T.npz',\n",
       " 'nma/R82W-P127F.npz',\n",
       " 'nma/N87S-K105V-D135R-R84Q-K154C.npz',\n",
       " 'nma/Q110T-A112N-C115N-R155Q.npz',\n",
       " 'nma/F100P-S141Q-K133E-F102Y-P127W.npz',\n",
       " 'nma/N91P-F100I-N128P-D136A.npz',\n",
       " 'nma/S118K-I149A-Q110M-M103P-P127C.npz',\n",
       " 'nma/P146M.npz',\n",
       " 'nma/I132Q-K105A.npz',\n",
       " 'nma/N107V-F104P-V96M.npz',\n",
       " 'nma/G126K-F144E-N139K-Q110P.npz',\n",
       " 'nma/V108N.npz',\n",
       " 'nma/K105W-I149Q-T114N-K154P-D122M.npz',\n",
       " 'nma/C99Q-D135V-D111M.npz',\n",
       " 'nma/H131F-R155L.npz',\n",
       " 'nma/I94W-G142L-S134G-G152L-R109G.npz',\n",
       " 'nma/R84Q-C115G-P97K-P95M-G147S.npz',\n",
       " 'nma/P86K.npz',\n",
       " 'nma/P95M-D122E-R155D.npz',\n",
       " 'nma/I78P.npz',\n",
       " 'nma/D135L-P86H-F100I-F102R.npz',\n",
       " 'nma/S141D.npz',\n",
       " 'nma/G152F-E83H-P146Q-R109Y.npz',\n",
       " 'nma/V150I-D111P-E83I-M103N-N91F.npz',\n",
       " 'nma/D93I.npz',\n",
       " 'nma/D90S.npz',\n",
       " 'nma/S118A.npz',\n",
       " 'nma/G126M-N107F.npz',\n",
       " 'nma/D143N-G113W.npz',\n",
       " 'nma/K154I.npz',\n",
       " 'nma/K120D-Q110L.npz',\n",
       " 'nma/K154E-D136N-N139T-L151D-E83Q.npz',\n",
       " 'nma/K133P-V150N-P86D-V108K-N128M.npz',\n",
       " 'nma/M121G.npz',\n",
       " 'nma/F89A-G142F-W129C.npz',\n",
       " 'nma/W148R-R82F.npz',\n",
       " 'nma/H131R-M103H.npz',\n",
       " 'nma/V96W-I94D-N87T.npz',\n",
       " 'nma/W119P-P97Y-G113R-V150Q.npz',\n",
       " 'nma/Y116T-P156L.npz',\n",
       " 'nma/L151P-G157P-F102K-F144G-G126V.npz',\n",
       " 'nma/P156C-K120T-N107D-D122A-M121C.npz',\n",
       " 'nma/L140K-D79L-W101M-A92Y-T114M.npz',\n",
       " 'nma/D143T.npz',\n",
       " 'nma/D136Y.npz',\n",
       " 'nma/Q110Y-A92L-P86D.npz',\n",
       " 'nma/C115G-G113V-V130Q-C138I-V108Y.npz',\n",
       " 'nma/Q110P-M103E-D135W.npz',\n",
       " 'nma/W101I-S134R.npz',\n",
       " 'nma/V125T-N128Q.npz',\n",
       " 'nma/I149Q-K133Y-S141K.npz',\n",
       " 'nma/S81F-I94D.npz',\n",
       " 'nma/D79K-V150P-G142T.npz',\n",
       " 'nma/K124A-N87D-P95D.npz',\n",
       " 'nma/S134M-C138G-N128Y.npz',\n",
       " 'nma/F144V-K120C-V125P.npz',\n",
       " 'nma/V130R-H131A.npz',\n",
       " 'nma/E83R-P97R.npz',\n",
       " 'nma/I132H-P95K-S141F-W119E.npz',\n",
       " 'nma/S141A-Y116H.npz',\n",
       " 'nma/N106E-N137W-N128T-P97V.npz',\n",
       " 'nma/K124R-W101D-N137G-P95Y.npz',\n",
       " 'nma/K133N-K120P-R82W-I94C.npz',\n",
       " 'nma/K120F-D85I-M123A-R109P-K133F.npz',\n",
       " 'nma/W101I.npz',\n",
       " 'nma/N139W-M103C-M121Y.npz',\n",
       " 'nma/F88C-M123Q-K105L-N106A.npz',\n",
       " 'nma/S141I-F158A-W148G-D90M.npz',\n",
       " 'nma/L80N-F100S-S81Q-G152S.npz',\n",
       " 'nma/M123I-W119M-W148D.npz',\n",
       " 'nma/V96W-P145G-Q110T.npz',\n",
       " 'nma/P86H-A92E-G126I-I94T.npz',\n",
       " 'nma/D143S-A92P-W148A.npz',\n",
       " 'nma/S134K-V96G.npz',\n",
       " 'nma/G142T-D90P-G126W-K154A-P127Q.npz',\n",
       " 'nma/C115M-N106T-R84P-N107P-C138V.npz',\n",
       " 'nma/N106E-D85W-F158L-G142D-D122V.npz',\n",
       " 'nma/N91G-S141M.npz',\n",
       " 'nma/E83W-K124W-P156H.npz',\n",
       " 'nma/C99A-P86L.npz',\n",
       " 'nma/N137R-K154E-K120G-P86V.npz',\n",
       " 'nma/D135Q-K133W.npz',\n",
       " 'nma/D136T-D122T-D79P-D135T-F104T.npz',\n",
       " 'nma/M103P-F158M-N128H.npz',\n",
       " 'nma/V125G-W129Q.npz',\n",
       " 'nma/F104V-D85A-G147D-D136M.npz',\n",
       " 'nma/D136V-C138A.npz',\n",
       " 'nma/P86T-P127F-W148S.npz',\n",
       " 'nma/P146N-K105N.npz',\n",
       " 'nma/E83V.npz',\n",
       " 'nma/D111R-G113W-V130S-F88L.npz',\n",
       " 'nma/V96G-V108W-M123I-G157T.npz',\n",
       " 'nma/N106G-D111Q-L140N-I149W.npz',\n",
       " 'nma/D111W-A92E.npz',\n",
       " 'nma/F89T-I94V-F158M-G147I-K120H.npz',\n",
       " 'nma/I132P-N107M.npz',\n",
       " 'nma/G147P.npz',\n",
       " 'nma/R109I-H131M-F102I.npz',\n",
       " 'nma/M121P-R155N-N128P-E98W.npz',\n",
       " 'nma/N128T-S141N-K105W.npz',\n",
       " 'nma/S141C-V130Q.npz',\n",
       " 'nma/W119I-L151D.npz',\n",
       " 'nma/G142V-L151G-C99N-D143F.npz',\n",
       " 'nma/P97V-V130F-N128Y-D85K-P95F.npz',\n",
       " 'nma/G147H-S134I.npz',\n",
       " 'nma/N87I-S134W-G157K-T114R-W101P.npz',\n",
       " 'nma/D122S-T114Q-R82I.npz',\n",
       " 'nma/G142M-M123K-N137G.npz',\n",
       " 'nma/K124V-K105G-Y116R-D135E.npz',\n",
       " 'nma/W119S.npz',\n",
       " 'nma/P97Q-N128W-V125T-P156S-T114M.npz',\n",
       " 'nma/D85E-D143A.npz',\n",
       " 'nma/V108W.npz',\n",
       " 'nma/M121T-R84F-N128A-R155N-K153A.npz',\n",
       " 'nma/F144M.npz',\n",
       " 'nma/A92C-G152D-N128E-M123F-A112S.npz',\n",
       " 'nma/G142H.npz',\n",
       " 'nma/W119N-S141W-D143A-G147K.npz',\n",
       " 'nma/F100S-D136M-K154C-P156D.npz',\n",
       " 'nma/F88W-F104R-S118I.npz',\n",
       " 'nma/N106C-K120R-D79N-V130T-S141V.npz',\n",
       " 'nma/K120Y-R155I-K153A-D90G.npz',\n",
       " 'nma/S117R.npz',\n",
       " 'nma/V108E-N107R-C138T-C115T.npz',\n",
       " 'nma/C138D-V150P-S134P-I149Y.npz',\n",
       " 'nma/T114R-N139Y-W129T-S118I.npz',\n",
       " 'nma/D135K.npz',\n",
       " 'nma/F88Y.npz',\n",
       " 'nma/P145N-K133Q-S118R-D135S.npz',\n",
       " 'nma/F100Y-G157R.npz',\n",
       " 'nma/V130N-E83W-S141L-W129Q-G147Q.npz',\n",
       " 'nma/P127I-V150R-F89E-L151W-S134K.npz',\n",
       " 'nma/G142L-R155M-G152E-F89Y.npz',\n",
       " 'nma/V125W-E83T-V96K-V108C-K133M.npz',\n",
       " 'nma/F144S-W101D-K105D-V96W.npz',\n",
       " 'nma/F89A-M121G.npz',\n",
       " 'nma/V150H-C99D-V130L-E98D-R109L.npz',\n",
       " 'nma/I78Q-G142P.npz',\n",
       " 'nma/D143E-G142H-Q110M-G113H-R109K.npz',\n",
       " 'nma/W101Y-C138I.npz',\n",
       " 'nma/V108A-S117F.npz',\n",
       " 'nma/L80D-P86V-D143G-R155Q-V150Y.npz',\n",
       " 'nma/D90R-P95M-A112L.npz',\n",
       " 'nma/L140A-D136S-D90R-I78K.npz',\n",
       " 'nma/V96N-S141F-G142E.npz',\n",
       " 'nma/R155G-F88C-V150W.npz',\n",
       " 'nma/K133N.npz',\n",
       " 'nma/N139K.npz',\n",
       " 'nma/E98V-W119N.npz',\n",
       " 'nma/M103F-S117I-G126E-F88H.npz',\n",
       " 'nma/V150F-D136R-V130S-C138A.npz',\n",
       " 'nma/G152M-A92V-M123W.npz',\n",
       " 'nma/P97I-P156V-G113F-N87D-F104R.npz',\n",
       " 'nma/S118P-V130F-E98F-P146Y-R82S.npz',\n",
       " 'nma/I78T.npz',\n",
       " 'nma/H131M-M103G.npz',\n",
       " 'nma/N91G-D135I.npz',\n",
       " 'nma/F158Y-F104V-M103I-K153I.npz',\n",
       " 'nma/F104P-S141H.npz',\n",
       " 'nma/D90V.npz',\n",
       " 'nma/K133H-W129G-L140F.npz',\n",
       " 'nma/R109Q-S134H-L151W-C99H.npz',\n",
       " 'nma/M121K.npz',\n",
       " 'nma/I132S.npz',\n",
       " 'nma/E83A-F88Y-P95N-V96Q.npz',\n",
       " 'nma/S141V.npz',\n",
       " 'nma/E98C-E83K-C138S.npz',\n",
       " 'nma/K105Y-F144C-R84K.npz',\n",
       " 'nma/W101P-P146V-K133V-F89I.npz',\n",
       " 'nma/S134E.npz',\n",
       " 'nma/V96E.npz',\n",
       " 'nma/V125L-V108S-D90M-K153H-P95R.npz',\n",
       " 'nma/N137I-P95N-D135I.npz',\n",
       " 'nma/K105V-G126I.npz',\n",
       " 'nma/M121P-S118H.npz',\n",
       " 'nma/M103N-F102C.npz',\n",
       " 'nma/F100Y-N106M-F102L-S81D-W119A.npz',\n",
       " 'nma/R84H-G147M.npz',\n",
       " 'nma/F89H-V150P-D135H-S81G.npz',\n",
       " 'nma/S141D-F158V-D93I.npz',\n",
       " 'nma/C138I-N139E-F88C-P127N-P97H.npz',\n",
       " 'nma/M123R-M121A-K133T-D122F.npz',\n",
       " 'nma/V96L-A112I-M123K.npz',\n",
       " 'nma/D136Y-E98L-K154Y-P86N-N91D.npz',\n",
       " 'nma/L80Y-T114C-S118K.npz',\n",
       " 'nma/V150I.npz',\n",
       " 'nma/D143N-G147R-N107C-G126Q-D111E.npz',\n",
       " 'nma/V150T-K105P-G157C-W148T-P86K.npz',\n",
       " 'nma/S141L.npz',\n",
       " 'nma/G142K-A112W-Q110F-L151D.npz',\n",
       " 'nma/A112T-F158D-W119Q.npz',\n",
       " 'nma/W101A.npz',\n",
       " 'nma/D85N-F158C-Y116T.npz',\n",
       " 'nma/N91H-R84I-N137Y.npz',\n",
       " 'nma/V130T-F100T-F88G-M121V.npz',\n",
       " 'nma/L140V-P156N-W119L.npz',\n",
       " 'nma/D136M-P156T-G157P-P145L-P127W.npz',\n",
       " 'nma/N107M.npz',\n",
       " 'nma/N137W-P95A-F100P-Y116T-D85M.npz',\n",
       " 'nma/D79M-N139V-K133S.npz',\n",
       " 'nma/S81W-C138R-V96L-V150S-A92R.npz',\n",
       " 'nma/W148M-F144E-K154C-A112K-V130S.npz',\n",
       " 'nma/K153H-D79H-E83C-G157F.npz',\n",
       " 'nma/M121N-P145V-G147V-N137Q-G126R.npz',\n",
       " 'nma/Q110H-N128H-N137F-V96G.npz',\n",
       " 'nma/F104H.npz',\n",
       " 'nma/V108A-I94C-G152Y-D90K.npz',\n",
       " 'nma/R155L-V130A-G113A-D122E.npz',\n",
       " 'nma/P127N-P86G.npz',\n",
       " 'nma/A112T-P146F.npz',\n",
       " 'nma/H131I-L80T-R82A.npz',\n",
       " 'nma/R155N-I94P-V130E-P146D.npz',\n",
       " 'nma/C138M-D135F-G142S-S117D.npz',\n",
       " 'nma/S117M-G157H-K154Y.npz',\n",
       " 'nma/F104A-M103E.npz',\n",
       " 'nma/W119A-D79G-N91H-G113N.npz',\n",
       " 'nma/I94A-P95N.npz',\n",
       " 'nma/M123Q-S141W-H131C.npz',\n",
       " 'nma/M121P-D143I.npz',\n",
       " 'nma/Q110C-I94T-E98C-K105F-I149H.npz',\n",
       " 'nma/R155Y.npz',\n",
       " 'nma/R155H.npz',\n",
       " 'nma/I78V-S141K-L151D-C99F-F89V.npz',\n",
       " 'nma/L140W-K153C.npz',\n",
       " 'nma/N91A-F89H-G147R-F102G.npz',\n",
       " 'nma/K120M-M103P-R155G-K105F-S118C.npz',\n",
       " 'nma/E98Q-M103Y.npz',\n",
       " 'nma/D111P-A92R.npz']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mut_df = pd.read_csv('mutant_library/mutant_library.csv')\n",
    "sequences = mut_df['sequence'].tolist()\n",
    "nma_paths = [f\"nma/{mut_string}.npz\" for mut_string in mut_df['mut']]\n",
    "\n",
    "nma_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "644d6f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # This section defines where your fine-tuned model and logs will be saved.\n",
    "    \"file_path\": {\n",
    "        \"save_dir\": \"models/esmdance-mutant-nma-fine-tuned/\", \n",
    "    },\n",
    "    \n",
    "    # General training settings.\n",
    "    \"training\": {\n",
    "        \"random_seed\": 42,\n",
    "        \"dropout\": 0.1,\n",
    "        \n",
    "        # You should adjust these based on how often you want to save and log.\n",
    "        # For a shorter fine-tuning run, you'll want to save more frequently.\n",
    "        \"save_per_epoch\": 1, # It's easier to think in epochs for fine-tuning.\n",
    "        \n",
    "        # --- CRITICAL CHANGE 1: Feature Indices ---\n",
    "        # This now correctly maps to your 3 residue-level and 3 pairwise NMA features.\n",
    "        \"res_feature_idx\": {\n",
    "            'nma_residue1': [0],\n",
    "            'nma_residue2': [1],\n",
    "            'nma_residue3': [2],\n",
    "        },\n",
    "        \"pair_feature_idx\": {\n",
    "            'nma_pair1': [0],\n",
    "            'nma_pair2': [1],\n",
    "            'nma_pair3': [2],\n",
    "        },\n",
    "    },\n",
    "\n",
    "    # --- CRITICAL CHANGE 2: Simplified Training Schedule ---\n",
    "    # This block is now tailored for your specific fine-tuning task.\n",
    "    \"esmdance\": {\n",
    "        \"freeze_esm\": True,      # Correct for ESMDance fine-tuning.\n",
    "        \"randomize_esm\": False,\n",
    "        \n",
    "        # All your sequences are 158, so we set one max_len.\n",
    "        # We add a little buffer, but it could be exactly 158.\n",
    "        \"max_len\": 256,\n",
    "        \n",
    "        # Define training by epochs, which is more intuitive for a fixed dataset.\n",
    "        \"num_epochs\": 20, # Adjust this based on how your loss behaves.\n",
    "        \n",
    "        # Set a single batch size. Adjust based on your GPU memory.\n",
    "        \"batch_size\": 4,\n",
    "        \n",
    "        # Gradient accumulation helps simulate a larger batch size.\n",
    "        # Effective batch size = batch_size * gradient_accumulation_steps\n",
    "        # Example: 8 * 4 = 32\n",
    "        \"gradient_accumulation_steps\": 4, \n",
    "    },\n",
    "\n",
    "    # Optimizer settings. These are generally good starting points.\n",
    "    \"optimizer\": {\n",
    "        \"peak_lr\": 1e-4,\n",
    "        \"epsilon\": 1e-8,\n",
    "        \"betas\": (0.9, 0.98),\n",
    "        \"weight_decay\": 0.01,\n",
    "        \"warmup_steps\": 200, # Number of steps for learning rate warmup.\n",
    "    },\n",
    "\n",
    "    # --- CRITICAL CHANGE 3: Model Output Dimensions ---\n",
    "    \"model_35M\": {\n",
    "        \"model_id\": \"facebook/esm2_t12_35M_UR50D\",\n",
    "        \"atten_dim\": 240,\n",
    "        \"embed_dim\": 480,\n",
    "        \n",
    "        # These now match your NMA-only data.\n",
    "        \"pair_out_dim\": 3, # Was 13. Now 3 for your 3 ANM correlation matrices.\n",
    "        \"res_out_dim\": 3,  # Was 50. Now 3 for your 3 GNM fluctuation vectors.\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ba844a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "full_dataset = FineTuneNMADataset(sequences, nma_paths)\n",
    "\n",
    "# Split data into training and validation sets (e.g., 90% train, 10% val)\n",
    "train_size = int(0.9 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=config['esmdance']['batch_size'], \n",
    "    shuffle=True, \n",
    "    collate_fn=collate_fn_nma\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config['esmdance']['batch_size'],\n",
    "    shuffle=False, # No need to shuffle validation data\n",
    "    collate_fn=collate_fn_nma\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09bcb66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import EsmModel\n",
    "from huggingface_hub import PyTorchModelHubMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ba370d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESMwrap(nn.Module, PyTorchModelHubMixin):\n",
    "    def __init__(self, esm2_select, model_select):\n",
    "        super().__init__()\n",
    "        # Load the ESM2 model\n",
    "        self.esm2 = EsmModel.from_pretrained(config[esm2_select]['model_id'])\n",
    "        self.freeze_esm = config[model_select]['freeze_esm']\n",
    "\n",
    "        # Freeze self.esm2 parameters if freeze_esm is True\n",
    "        if self.freeze_esm:\n",
    "            for param in self.esm2.parameters():\n",
    "                param.requires_grad = False\n",
    "            self.esm2.eval()  # Set to evaluation mode\n",
    "\n",
    "        # Randomize self.esm2 parameters if randomize_esm is True\n",
    "        if config[model_select]['randomize_esm']:\n",
    "            self.randomize_model(self.esm2)\n",
    "\n",
    "        # dimensions of input and output\n",
    "        embed_dim = config[esm2_select]['embed_dim']\n",
    "        res_out_dim = config[esm2_select]['res_out_dim']\n",
    "        atten_dim = config[esm2_select]['atten_dim']\n",
    "        pair_out_dim = config[esm2_select]['pair_out_dim']\n",
    "\n",
    "        # Residue-level prediction layer\n",
    "        self.res_pred_nn = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm(embed_dim),\n",
    "            nn.Dropout(config['training']['dropout']),  # Apply dropout after LayerNorm\n",
    "            nn.Linear(embed_dim, res_out_dim)\n",
    "        )\n",
    "\n",
    "        # transform res embedding for Pairwise prediction\n",
    "        self.res_transform_nn = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm(embed_dim),\n",
    "            nn.Dropout(config['training']['dropout']),  # Apply dropout after LayerNorm\n",
    "            nn.Linear(embed_dim, embed_dim*2)\n",
    "        )\n",
    "\n",
    "        # Pairwise prediction layer\n",
    "        self.pair_middle_linear = nn.Linear(embed_dim*2, atten_dim)\n",
    "        self.pair_pred_linear = nn.Linear(atten_dim + atten_dim, pair_out_dim)\n",
    "\n",
    "        # Activation functions\n",
    "        self.gelu = nn.GELU()\n",
    "        self.softplus = nn.Softplus(beta=1.0, threshold=2.0)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "        # Feature indices from config\n",
    "        self.res_feature_idx = config['training']['res_feature_idx']\n",
    "        self.pair_feature_idx = config['training']['pair_feature_idx']\n",
    "\n",
    "        # Initialize biases to zero\n",
    "        self._init_bias_zero()\n",
    "\n",
    "    def randomize_model(self, model):\n",
    "        \"\"\" Randomize the parameters of the given model. \"\"\"\n",
    "        for module_ in model.named_modules():\n",
    "            if isinstance(module_[1], (torch.nn.Linear, torch.nn.Embedding)):\n",
    "                if hasattr(module_[1], 'bias') and module_[1].bias is not None:\n",
    "                    module_[1].bias.data.zero_()\n",
    "                if hasattr(module_[1], 'weight'):\n",
    "                    if 'query' in module_[0] or 'key' in module_[0] or 'value' in module_[0]:\n",
    "                        module_[1].weight = nn.init.xavier_uniform_(module_[1].weight, gain=1 / math.sqrt(2))\n",
    "                    else:\n",
    "                        module_[1].weight = nn.init.xavier_uniform_(module_[1].weight)\n",
    "                            \n",
    "            elif isinstance(module_[1], nn.LayerNorm):\n",
    "                if hasattr(module_[1], 'bias'):\n",
    "                    module_[1].bias.data.zero_()\n",
    "                if hasattr(module_[1], 'weight'):\n",
    "                    module_[1].weight.data.fill_(1.0)\n",
    "                \n",
    "            elif isinstance(module_[1], nn.Dropout):\n",
    "                module_[1].p = config['training']['dropout']\n",
    "\n",
    "\n",
    "    def _init_bias_zero(self):\n",
    "        \"\"\" Set all biases in the model (excluding esm2) to zero. \"\"\"\n",
    "        for name, module in self.named_modules():\n",
    "            if \"esm2\" not in name and isinstance(module, nn.Linear) and module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "\n",
    "\n",
    "    def forward(self, inputs, return_res_emb=False, return_attention_map=False, return_res_pred=True, return_pair_pred=True):\n",
    "        output = {}\n",
    "\n",
    "        # ESM forward pass, Ensure no gradients are stored for frozen ESM2\n",
    "        if self.freeze_esm:\n",
    "            with torch.no_grad():\n",
    "                esm_output = self.esm2(**inputs, output_attentions=True)\n",
    "        else:\n",
    "            esm_output = self.esm2(**inputs, output_attentions=True)\n",
    "\n",
    "        res_emb = esm_output['last_hidden_state']\n",
    "        pair_atten = torch.cat(esm_output['attentions'], dim=1).permute(0, 2, 3, 1)\n",
    "\n",
    "        if return_res_emb:\n",
    "            output['res_emb'] = res_emb\n",
    "        if return_attention_map:\n",
    "            output['attention_map'] = pair_atten\n",
    "\n",
    "        # Residue-level prediction\n",
    "        if return_res_pred:\n",
    "            res_pred = self.res_pred_nn(res_emb)\n",
    "            for feature in self.res_feature_idx:\n",
    "                if feature == 'rmsf_nor':\n",
    "                    # Normalized RMSF (max = 1)\n",
    "                    output[feature] = self.sigmoid(res_pred[:, :, self.res_feature_idx[feature]])\n",
    "                elif feature in ['ss', 'chi', 'phi', 'psi']:\n",
    "                    # Secondary structure, chi, phi, psi sum up to 1\n",
    "                    output[feature] = self.softmax(res_pred[:, :, self.res_feature_idx[feature]])\n",
    "                else:\n",
    "                    # All other features are non-negative\n",
    "                    output[feature] = self.softplus(res_pred[:, :, self.res_feature_idx[feature]])\n",
    "\n",
    "        # Pairwise transformation\n",
    "        s = self.res_transform_nn(res_emb)\n",
    "        q, k = s.chunk(2, dim=-1)\n",
    "        prod = q[:, None, :, :] * k[:, :, None, :]\n",
    "        diff = q[:, None, :, :] - k[:, :, None, :]\n",
    "        pair_middle = self.gelu(self.pair_middle_linear(torch.cat([prod, diff], dim=-1)))\n",
    "\n",
    "        # Pairwise prediction\n",
    "        if return_pair_pred:\n",
    "            pair_pred = self.pair_pred_linear(torch.cat([pair_middle, pair_atten], dim=-1))\n",
    "\n",
    "            for feature in self.pair_feature_idx:\n",
    "                if feature in ['corr', 'nma_pair1', 'nma_pair2', 'nma_pair3']:\n",
    "                    # Co-movement and NMA co-movement correlations: range [-1, 1]\n",
    "                    output[feature] = self.sigmoid(pair_pred[:, :, :, self.pair_feature_idx[feature]]) * 2 - 1.0\n",
    "                else:\n",
    "                    # All interaction features are non-negative\n",
    "                    output[feature] = self.softplus(pair_pred[:, :, :, self.pair_feature_idx[feature]])\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e73d2f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97759489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(config['training']['random_seed'])\n",
    "np.random.seed(config['training']['random_seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3132fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "# Create save directory from config\n",
    "save_dir = Path(config['file_path']['save_dir'])\n",
    "save_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "710ac295",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t12_35M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = ESMwrap(esm2_select='model_35M', model_select='esmdance').to(device)\n",
    "checkpoint = torch.load('pretrained_weights/esmdance_update_60000.pt')\n",
    "model_state_dict = model.state_dict()\n",
    "\n",
    "filtered_state_dict = {\n",
    "            k: v for k, v in checkpoint.items() \n",
    "            if k in model_state_dict and v.shape == model_state_dict[k].shape\n",
    "        }\n",
    "        \n",
    "# Update our new model's state dict with the filtered weights\n",
    "model_state_dict.update(filtered_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4841bbaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(model_state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b0c9b501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===========================================================================================================================================================\n",
       "Layer (type (var_name))                                                     Input Shape          Output Shape         Param #              Trainable\n",
       "===========================================================================================================================================================\n",
       "ESMwrap (ESMwrap)                                                           [1, 160]             [1, 160, 160, 1]     --                   Partial\n",
       "├─EsmModel (esm2)                                                           --                   [1, 20, 160, 160]    241                  False\n",
       "│    └─EsmEmbeddings (embeddings)                                           --                   [1, 160, 480]        492,480              False\n",
       "│    │    └─Embedding (word_embeddings)                                     [1, 160]             [1, 160, 480]        (15,840)             False\n",
       "│    └─EsmEncoder (encoder)                                                 [1, 160, 480]        [1, 20, 160, 160]    --                   False\n",
       "│    │    └─ModuleList (layer)                                              --                   --                   (33,252,480)         False\n",
       "│    │    └─LayerNorm (emb_layer_norm_after)                                [1, 160, 480]        [1, 160, 480]        (960)                False\n",
       "│    └─EsmPooler (pooler)                                                   [1, 160, 480]        [1, 480]             --                   False\n",
       "│    │    └─Linear (dense)                                                  [1, 480]             [1, 480]             (230,880)            False\n",
       "│    │    └─Tanh (activation)                                               [1, 480]             [1, 480]             --                   --\n",
       "├─Sequential (res_pred_nn)                                                  [1, 160, 480]        [1, 160, 3]          --                   True\n",
       "│    └─Linear (0)                                                           [1, 160, 480]        [1, 160, 480]        230,880              True\n",
       "│    └─GELU (1)                                                             [1, 160, 480]        [1, 160, 480]        --                   --\n",
       "│    └─LayerNorm (2)                                                        [1, 160, 480]        [1, 160, 480]        960                  True\n",
       "│    └─Dropout (3)                                                          [1, 160, 480]        [1, 160, 480]        --                   --\n",
       "│    └─Linear (4)                                                           [1, 160, 480]        [1, 160, 3]          1,443                True\n",
       "├─Softplus (softplus)                                                       [1, 160, 1]          [1, 160, 1]          --                   --\n",
       "├─Softplus (softplus)                                                       [1, 160, 1]          [1, 160, 1]          --                   --\n",
       "├─Softplus (softplus)                                                       [1, 160, 1]          [1, 160, 1]          --                   --\n",
       "├─Sequential (res_transform_nn)                                             [1, 160, 480]        [1, 160, 960]        --                   True\n",
       "│    └─Linear (0)                                                           [1, 160, 480]        [1, 160, 480]        230,880              True\n",
       "│    └─GELU (1)                                                             [1, 160, 480]        [1, 160, 480]        --                   --\n",
       "│    └─LayerNorm (2)                                                        [1, 160, 480]        [1, 160, 480]        960                  True\n",
       "│    └─Dropout (3)                                                          [1, 160, 480]        [1, 160, 480]        --                   --\n",
       "│    └─Linear (4)                                                           [1, 160, 480]        [1, 160, 960]        461,760              True\n",
       "├─Linear (pair_middle_linear)                                               [1, 160, 160, 960]   [1, 160, 160, 240]   230,640              True\n",
       "├─GELU (gelu)                                                               [1, 160, 160, 240]   [1, 160, 160, 240]   --                   --\n",
       "├─Linear (pair_pred_linear)                                                 [1, 160, 160, 480]   [1, 160, 160, 3]     1,443                True\n",
       "├─Sigmoid (sigmoid)                                                         [1, 160, 160, 1]     [1, 160, 160, 1]     --                   --\n",
       "├─Sigmoid (sigmoid)                                                         [1, 160, 160, 1]     [1, 160, 160, 1]     --                   --\n",
       "├─Sigmoid (sigmoid)                                                         [1, 160, 160, 1]     [1, 160, 160, 1]     --                   --\n",
       "===========================================================================================================================================================\n",
       "Total params: 35,151,847\n",
       "Trainable params: 1,158,966\n",
       "Non-trainable params: 33,992,881\n",
       "Total mult-adds (Units.MEGABYTES): 34.66\n",
       "===========================================================================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 135.79\n",
       "Params size (MB): 138.64\n",
       "Estimated Total Size (MB): 274.43\n",
       "==========================================================================================================================================================="
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "batch_size = 1\n",
    "sequence_length = 160 # 158 residues + 2 special tokens\n",
    "\n",
    "dummy_input_ids = torch.randint(0, 33, (batch_size, sequence_length), dtype=torch.long)\n",
    "dummy_attention_mask = torch.ones(batch_size, sequence_length, dtype=torch.long)\n",
    "\n",
    "dummy_inputs_dict = {\n",
    "    \"input_ids\": dummy_input_ids,\n",
    "    \"attention_mask\": dummy_attention_mask\n",
    "}\n",
    "\n",
    "# This tells torchinfo to pass the dictionary as a single positional argument,\n",
    "# which matches your model's forward(self, inputs) signature.\n",
    "input_data_for_summary = (dummy_inputs_dict,)\n",
    "\n",
    "summary(\n",
    "    model,\n",
    "    # Pass the TUPLE containing the dictionary\n",
    "    input_data=input_data_for_summary,\n",
    "    \n",
    "    # The other summary arguments are for torchinfo itself and will no longer be passed to your model\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "    col_width=20,\n",
    "    row_settings=[\"var_names\"],\n",
    "    device=\"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "864bbd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 1,158,966\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.amp import GradScaler, autocast\n",
    "\n",
    "loss_function = nn.MSELoss(reduction='none') # Use reduction='none' for custom masking\n",
    "trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "print(f\"Total trainable parameters: {sum(p.numel() for p in trainable_params):,}\")\n",
    "optimizer = AdamW(trainable_params, lr=config['optimizer']['peak_lr'], betas=config['optimizer']['betas'])\n",
    "\n",
    "scaler = GradScaler() # For mixed-precision training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c66bc808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fine-tuning for 20 epochs...\n",
      "\n",
      "Epoch 1/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 [Training]: 100%|██████████| 68/68 [00:06<00:00,  9.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.8207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 18.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3045\n",
      "\n",
      "Epoch 2/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 [Training]: 100%|██████████| 68/68 [00:01<00:00, 38.05it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 23.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2367\n",
      "\n",
      "Epoch 3/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 15.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 24.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2063\n",
      "\n",
      "Epoch 4/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 16.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 23.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1814\n",
      "\n",
      "Epoch 5/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 15.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 22.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1535\n",
      "\n",
      "Epoch 6/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 15.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 23.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1317\n",
      "\n",
      "Epoch 7/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 25.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1160\n",
      "\n",
      "Epoch 8/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 15.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 24.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1012\n",
      "\n",
      "Epoch 9/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 [Training]: 100%|██████████| 68/68 [00:01<00:00, 35.99it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 24.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0864\n",
      "\n",
      "Epoch 10/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 15.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 23.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0736\n",
      "\n",
      "Epoch 11/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 15.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 23.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0631\n",
      "\n",
      "Epoch 12/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 15.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 24.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0536\n",
      "\n",
      "Epoch 13/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 15.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 21.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0452\n",
      "\n",
      "Epoch 14/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 15.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 23.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0381\n",
      "\n",
      "Epoch 15/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 16.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 22.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0321\n",
      "\n",
      "Epoch 16/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 [Training]: 100%|██████████| 68/68 [00:01<00:00, 36.08it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 25.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0279\n",
      "\n",
      "Epoch 17/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 16.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 24.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0242\n",
      "\n",
      "Epoch 18/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 15.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 26.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0214\n",
      "\n",
      "Epoch 19/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 16.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 22.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0195\n",
      "\n",
      "Epoch 20/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 14.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 23.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.amp import autocast\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = config['esmdance']['num_epochs']\n",
    "grad_accum_steps = config['esmdance']['gradient_accumulation_steps']\n",
    "\n",
    "print(f\"Starting fine-tuning for {num_epochs} epochs...\")\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'\\nEpoch {epoch+1}/{num_epochs}\\n------------------------------')\n",
    "    # =======================================\n",
    "    #               TRAINING\n",
    "    # =======================================\n",
    "    model.train() # Set the model to training mode\n",
    "    total_train_loss = 0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} [Training]\")):\n",
    "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "        labels = {key: val.to(device) for key, val in labels.items()}\n",
    "        \n",
    "        with autocast(device_type='cuda', dtype=torch.float16):\n",
    "            predictions = model(inputs)\n",
    "            \n",
    "            # --- Loss Calculation ---\n",
    "            res_loss = 0\n",
    "            res_mask = labels['nma_residue1'] != -1\n",
    "            for k in ['nma_residue1', 'nma_residue2', 'nma_residue3']:\n",
    "                pred_k = predictions[k].squeeze(-1)\n",
    "                label_k = labels[k]\n",
    "                element_wise_loss = loss_function(pred_k, label_k)\n",
    "                valid_losses = element_wise_loss[res_mask]\n",
    "                res_loss += valid_losses.mean()\n",
    "\n",
    "            pair_loss = 0\n",
    "            pair_mask = labels['nma_pair1'] != -1\n",
    "            for k in ['nma_pair1', 'nma_pair2', 'nma_pair3']:\n",
    "                pred_pair_k = predictions[k].squeeze(-1)\n",
    "                label_pair_k = labels[k]\n",
    "                element_wise_loss = loss_function(pred_pair_k, label_pair_k)\n",
    "                valid_losses = element_wise_loss[pair_mask]\n",
    "                pair_loss += valid_losses.mean()\n",
    "            \n",
    "            loss = (3 * pair_loss + res_loss) / grad_accum_steps\n",
    "        \n",
    "        # --- Gradient Accumulation & Backpropagation ---\n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        if (i + 1) % grad_accum_steps == 0 or (i + 1) == len(train_loader):\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        total_train_loss += loss.item() * grad_accum_steps\n",
    "        \n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    print(f\"Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # =======================================\n",
    "    #              VALIDATION\n",
    "    # =======================================\n",
    "    model.eval() # Set the model to evaluation mode\n",
    "    total_val_loss = 0\n",
    "    \n",
    "    # Disable gradient calculations for validation to save memory and compute\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} [Validation]\")):\n",
    "            inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "            labels = {key: val.to(device) for key, val in labels.items()}\n",
    "            \n",
    "            # Forward pass only, still use autocast for consistency\n",
    "            with autocast(device_type='cuda', dtype=torch.float16):\n",
    "                predictions = model(inputs)\n",
    "\n",
    "                # --- Loss Calculation (Identical to training) ---\n",
    "                res_loss = 0\n",
    "                res_mask = labels['nma_residue1'] != -1\n",
    "                for k in ['nma_residue1', 'nma_residue2', 'nma_residue3']:\n",
    "                    pred_k = predictions[k].squeeze(-1)\n",
    "                    label_k = labels[k]\n",
    "                    element_wise_loss = loss_function(pred_k, label_k)\n",
    "                    valid_losses = element_wise_loss[res_mask]\n",
    "                    res_loss += valid_losses.mean()\n",
    "\n",
    "                pair_loss = 0\n",
    "                pair_mask = labels['nma_pair1'] != -1\n",
    "                for k in ['nma_pair1', 'nma_pair2', 'nma_pair3']:\n",
    "                    pred_pair_k = predictions[k].squeeze(-1)\n",
    "                    label_pair_k = labels[k]\n",
    "                    element_wise_loss = loss_function(pred_pair_k, label_pair_k)\n",
    "                    valid_losses = element_wise_loss[pair_mask]\n",
    "                    pair_loss += valid_losses.mean()\n",
    "                \n",
    "                # Note: We do NOT divide by grad_accum_steps for validation loss\n",
    "                val_loss = 3 * pair_loss + res_loss\n",
    "            \n",
    "            total_val_loss += val_loss.item()\n",
    "            \n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4802d3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = save_dir / \"esmdance_fine-tuned_with_nma_data.pth\"\n",
    "torch.save(model.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e20c17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
