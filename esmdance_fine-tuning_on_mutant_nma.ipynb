{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcd499fb",
   "metadata": {},
   "source": [
    "# Fine-tune ESMDance on Custom NMA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9be961ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a079220",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FineTuneNMADataset(Dataset):\n",
    "    \"\"\"A dataset for fine-tuning on custom NMA features from .npz files.\"\"\"\n",
    "    def __init__(self, sequences, nma_features_paths):\n",
    "        self.sequences = sequences\n",
    "        self.nma_features_paths = nma_features_paths\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t12_35M_UR50D\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        sequence = self.sequences[idx]\n",
    "        tokenized_output = self.tokenizer(sequence, return_tensors='pt')\n",
    "        inputs = {key: val.squeeze(0) for key, val in tokenized_output.items()}\n",
    "\n",
    "        # Load NMA features\n",
    "        nma_data = np.load(self.nma_features_paths[idx])\n",
    "        gnm_msf = torch.from_numpy(nma_data['gnm_msf']).float()\n",
    "        anm_cor = torch.from_numpy(nma_data['anm_cor']).float()\n",
    "\n",
    "        labels = {\n",
    "            'nma_residue1': gnm_msf[0],\n",
    "            'nma_residue2': gnm_msf[1],\n",
    "            'nma_residue3': gnm_msf[2],\n",
    "            'nma_pair1': anm_cor[0],\n",
    "            'nma_pair2': anm_cor[1],\n",
    "            'nma_pair3': anm_cor[2]\n",
    "        }\n",
    "        \n",
    "        return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cddf0bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_nma(batch):\n",
    "    \"\"\"\n",
    "    Collator function to pad sequences and features at the batch level.\n",
    "    This version correctly pads all labels to match the tokenized input length.\n",
    "    \"\"\"\n",
    "    batch_inputs = [item[0] for item in batch]\n",
    "    batch_labels = [item[1] for item in batch]\n",
    "\n",
    "    # --- Pad Inputs (This part was always correct) ---\n",
    "    padded_inputs = {}\n",
    "    padded_inputs['input_ids'] = pad_sequence(\n",
    "        [b['input_ids'] for b in batch_inputs], batch_first=True, padding_value=1\n",
    "    )\n",
    "    padded_inputs['attention_mask'] = pad_sequence(\n",
    "        [b['attention_mask'] for b in batch_inputs], batch_first=True, padding_value=0\n",
    "    )\n",
    "    \n",
    "    # This is the target length for all tensors (e.g., 160)\n",
    "    max_len = padded_inputs['input_ids'].shape[1]\n",
    "\n",
    "    # --- Pad Labels (CORRECTED LOGIC) ---\n",
    "    padded_labels = {}\n",
    "    for key in batch_labels[0].keys():\n",
    "        if 'residue' in key:\n",
    "            # --- THIS IS THE FIX ---\n",
    "            padded_tensors = []\n",
    "            for b in batch_labels:\n",
    "                tensor = b[key]  # Shape: (num_residues,) e.g., (158,)\n",
    "                # Manually pad each residue tensor to the full token length (160)\n",
    "                num_padding = max_len - tensor.shape[0]\n",
    "                padded_tensor = torch.nn.functional.pad(tensor, (0, num_padding), value=-1)\n",
    "                padded_tensors.append(padded_tensor)\n",
    "            # Stack the now correctly-sized tensors\n",
    "            padded_labels[key] = torch.stack(padded_tensors)\n",
    "        \n",
    "        elif 'pair' in key:\n",
    "            # The pairwise padding logic was already correct\n",
    "            padded_tensors = []\n",
    "            for b in batch_labels:\n",
    "                tensor = b[key]\n",
    "                n = tensor.shape[0]\n",
    "                padded_tensor = torch.nn.functional.pad(tensor, (0, max_len - n, 0, max_len - n), value=-1)\n",
    "                padded_tensors.append(padded_tensor)\n",
    "            padded_labels[key] = torch.stack(padded_tensors)\n",
    "\n",
    "    return padded_inputs, padded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f603420d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nma/G62M-V69N-R38M-C14H.npz',\n",
       " 'nma/S24M.npz',\n",
       " 'nma/K52E.npz',\n",
       " 'nma/T25E.npz',\n",
       " 'nma/K59T-A23Q-R15Y-V31Q-D49S.npz',\n",
       " 'nma/S55G-V28D.npz',\n",
       " 'nma/L2S-V10A-S24Y.npz',\n",
       " 'nma/V7D-D63I-A64N-Y46K.npz',\n",
       " 'nma/S55L-G26L-K3Y-L2K-C14V.npz',\n",
       " 'nma/D63T-I6L-V34F-G45I.npz',\n",
       " 'nma/V44M-K3F-L66E-D36S-A23K.npz',\n",
       " 'nma/D29N-K74H-K59E-K73A.npz',\n",
       " 'nma/E65T.npz',\n",
       " 'nma/K40R-S16P.npz',\n",
       " 'nma/Q4R-V43Y-N13A-L37E.npz',\n",
       " 'nma/L21G-L57R-V69H-V31R-A32K.npz',\n",
       " 'nma/D39V-K5G-Q68G-V10Y.npz',\n",
       " 'nma/S30F-A11W-S70Q-V43N.npz',\n",
       " 'nma/P50H-G35H-C14F-L2H.npz',\n",
       " 'nma/P50W-G47M-K9H-T25P.npz',\n",
       " 'nma/I41G-K40I-M12T.npz',\n",
       " 'nma/K3Y-K9S-S16A.npz',\n",
       " 'nma/G47I-V34Q-V31N-L2A.npz',\n",
       " 'nma/T25R-A32Q.npz',\n",
       " 'nma/V28L-D29T-L57G-Q68N-G26T.npz',\n",
       " 'nma/L33Y.npz',\n",
       " 'nma/R15E-V28M-M19F.npz',\n",
       " 'nma/K5N-G45S-V61K-S30D-A32T.npz',\n",
       " 'nma/D49K-G62C-I41K-M19H-R15I.npz',\n",
       " 'nma/L53R.npz',\n",
       " 'nma/G1A-L57I.npz',\n",
       " 'nma/A23Y-K74F-G27H.npz',\n",
       " 'nma/L53Q-L57W-K17Q-K40H.npz',\n",
       " 'nma/V22P.npz',\n",
       " 'nma/G1I-L53C.npz',\n",
       " 'nma/G35E-D63E.npz',\n",
       " 'nma/L33C-S55E-G1A-G45C.npz',\n",
       " 'nma/V22I-K59G-R58L-L21N.npz',\n",
       " 'nma/S55N-V10R.npz',\n",
       " 'nma/L21F-K3M-C14R-G45P.npz',\n",
       " 'nma/V10C-I48E.npz',\n",
       " 'nma/V44M-I41P-S55W-A23C-A18Q.npz',\n",
       " 'nma/A18L-I6A-G62A-I8H.npz',\n",
       " 'nma/V31N-Q4T.npz',\n",
       " 'nma/A72V-L66F-D36G-V31I-L53A.npz',\n",
       " 'nma/V10P-D29F.npz',\n",
       " 'nma/G62Q-G45I-K74I.npz',\n",
       " 'nma/K60T-G26R-V69D-A18C.npz',\n",
       " 'nma/N13M-D29E.npz',\n",
       " 'nma/L33E-L53N.npz',\n",
       " 'nma/V61H-D49G-V31T-I54K-L33R.npz',\n",
       " 'nma/P50E-A20V-E42C-I48F-G62F.npz',\n",
       " 'nma/V61K-K59L-K5H-E65Q-G62F.npz',\n",
       " 'nma/A32N-V44E-K52P-A20W.npz',\n",
       " 'nma/A11I-K17W-V31F.npz',\n",
       " 'nma/G47P-A72G.npz',\n",
       " 'nma/L53D-I6W-S16D-K5L.npz',\n",
       " 'nma/V10P.npz',\n",
       " 'nma/N13K-P50S-K52G-A64C.npz',\n",
       " 'nma/V43H-L53S-L57K-G47F-K73V.npz',\n",
       " 'nma/M12Q.npz',\n",
       " 'nma/V44P-D36T.npz',\n",
       " 'nma/A18T.npz',\n",
       " 'nma/A20V-L37M-S30E-S16M.npz',\n",
       " 'nma/V34T-T25R-M12W.npz',\n",
       " 'nma/I51Y-R15W.npz',\n",
       " 'nma/I48K-L53A-Q68K-K9I-V7M.npz',\n",
       " 'nma/A32T-G47S-E65S-P50M.npz',\n",
       " 'nma/I6Q-D49G.npz',\n",
       " 'nma/A18D-K52F-V69Q-I48T.npz',\n",
       " 'nma/S55Q-A72E-P50H.npz',\n",
       " 'nma/G35W-D39G-V43G.npz',\n",
       " 'nma/K74I-G27N.npz',\n",
       " 'nma/A18K.npz',\n",
       " 'nma/D36T-S24Q-A56I-K3P.npz',\n",
       " 'nma/G35A-V28E-V69L.npz',\n",
       " 'nma/A20N-I8K-R38P-N13H.npz',\n",
       " 'nma/T25S-G62F-V69W.npz',\n",
       " 'nma/L57Y-L2C-S24Q.npz',\n",
       " 'nma/L67K-A18Y-K3E-G27F-G1H.npz',\n",
       " 'nma/V61N-A72F-V7G-A23E-G1I.npz',\n",
       " 'nma/V34M-V7M-S30R-L37F-M19E.npz',\n",
       " 'nma/V7H-I6R-T25R.npz',\n",
       " 'nma/A56L-G35M.npz',\n",
       " 'nma/I54Y-V28F-I48V.npz',\n",
       " 'nma/G26S-V61T-K59C-D63N.npz',\n",
       " 'nma/K52I.npz',\n",
       " 'nma/G35S-V31W.npz',\n",
       " 'nma/V61C.npz',\n",
       " 'nma/I41E-L66D-V61H-A64R.npz',\n",
       " 'nma/V22S.npz',\n",
       " 'nma/V34C-N13P-S70H-A20C.npz',\n",
       " 'nma/V28P-M19Q-V22G-S55T-K3F.npz',\n",
       " 'nma/A18G-V44A-A23D.npz',\n",
       " 'nma/V22T-M19E-N13P-V43T-I41A.npz',\n",
       " 'nma/K74C-Y46I-E65R.npz',\n",
       " 'nma/C14W.npz',\n",
       " 'nma/G1M-I48M.npz',\n",
       " 'nma/K73E-L33K-M12P-A64R-K40S.npz',\n",
       " 'nma/Q71C-G62W-A56K.npz',\n",
       " 'nma/L33E-A56M-C14V-D29C-K40I.npz',\n",
       " 'nma/S70P-K17L-D39R-I8V-V31N.npz',\n",
       " 'nma/M12Q-N13R-K40W-S24H.npz',\n",
       " 'nma/S24F.npz',\n",
       " 'nma/N13W-E42M.npz',\n",
       " 'nma/L66M-G1N.npz',\n",
       " 'nma/K60R-A32L.npz',\n",
       " 'nma/V44T-A20V.npz',\n",
       " 'nma/C14Y-I48G-S30K-V22E-K74V.npz',\n",
       " 'nma/E65D.npz',\n",
       " 'nma/A18Q-G35N-P50G-K9L.npz',\n",
       " 'nma/G26A-I48A-V44T.npz',\n",
       " 'nma/V28K-D29G-C14L-E65R.npz',\n",
       " 'nma/S30N-V31S-D39H-L66R.npz',\n",
       " 'nma/Y46F-G62D-V28Y-I6M.npz',\n",
       " 'nma/I51H-R58G.npz',\n",
       " 'nma/K60I-L21H-K9C.npz',\n",
       " 'nma/G45H-L53K-C14R-Q4D.npz',\n",
       " 'nma/V28A-P50S-Q68S.npz',\n",
       " 'nma/K5G-D39G-I6E-K9D-I51P.npz',\n",
       " 'nma/T25F-K74L-V44T-A18H-V10H.npz',\n",
       " 'nma/R38L-A64C-L66P-T25V.npz',\n",
       " 'nma/I48E-A23V.npz',\n",
       " 'nma/K40G-I6M-V61C-L57M-V7H.npz',\n",
       " 'nma/D39L-K5E-M19H-K73V.npz',\n",
       " 'nma/K60T-G45R.npz',\n",
       " 'nma/L2Q-K5L.npz',\n",
       " 'nma/P50G-S24A-L66H-G1P-A11E.npz',\n",
       " 'nma/A18F-S16I-K17C.npz',\n",
       " 'nma/G26Q.npz',\n",
       " 'nma/A18P.npz',\n",
       " 'nma/V34G-I48D-S55L-D49G.npz',\n",
       " 'nma/S70C-A72R-M12C-V44M.npz',\n",
       " 'nma/P50L-A23D-K60I-V69R-K73D.npz',\n",
       " 'nma/T25G-A11H.npz',\n",
       " 'nma/V34S.npz',\n",
       " 'nma/S30L-A20L-K52D-T25R.npz',\n",
       " 'nma/L37I-E42F-A18D-G27S.npz',\n",
       " 'nma/D39C-L37A-S70E-E42A.npz',\n",
       " 'nma/M19V-D39K.npz',\n",
       " 'nma/A18Q.npz',\n",
       " 'nma/T25N-Y46Q.npz',\n",
       " 'nma/V69G.npz',\n",
       " 'nma/S70M-L37P-G27Q.npz',\n",
       " 'nma/M19N-S30Q-N13V-V10N.npz',\n",
       " 'nma/M12A-G45Y-K73Y.npz',\n",
       " 'nma/V61F-S24D-K5L-I41A.npz',\n",
       " 'nma/T25L-V44W-I8S-A56S-E42A.npz',\n",
       " 'nma/L37T-A23N-K74N.npz',\n",
       " 'nma/D36I-E42H.npz',\n",
       " 'nma/C14R-V34R-V10E-G26E.npz',\n",
       " 'nma/L57R.npz',\n",
       " 'nma/D29F-A23V-C14L-I6Q-M19I.npz',\n",
       " 'nma/L66V-A18R-K52V-Q71T-A23T.npz',\n",
       " 'nma/Q68S.npz',\n",
       " 'nma/Q68K.npz',\n",
       " 'nma/I41D-A23N.npz',\n",
       " 'nma/G45M-L21C-L37F.npz',\n",
       " 'nma/R58H.npz',\n",
       " 'nma/M19D-I41R-S70A.npz',\n",
       " 'nma/T25S-S16M-D39L-I8D.npz',\n",
       " 'nma/I6Q.npz',\n",
       " 'nma/A32T.npz',\n",
       " 'nma/R15N-K52R.npz',\n",
       " 'nma/M19D-L2Y-G62V.npz',\n",
       " 'nma/G45R-K9M-V28D-Q71Y.npz',\n",
       " 'nma/I41T-V44H-T25W.npz',\n",
       " 'nma/M12D-S55K.npz',\n",
       " 'nma/I48M-A72N-D29F-L57H.npz',\n",
       " 'nma/G62T-D49W.npz',\n",
       " 'nma/V7A-Y46K-A11L.npz',\n",
       " 'nma/S16M-Q4W-V28F-I41G-A56T.npz',\n",
       " 'nma/P50C-S70W-L21A-G35P-S24D.npz',\n",
       " 'nma/K5R-L33W-R58P-I54G.npz',\n",
       " 'nma/K17R-G47E-D29W.npz',\n",
       " 'nma/A20H-Y46Q-I54C-Q68K.npz',\n",
       " 'nma/V43N-V31F.npz',\n",
       " 'nma/D29R.npz',\n",
       " 'nma/S55N-L2G-A11I.npz',\n",
       " 'nma/E65V.npz',\n",
       " 'nma/A72C-D49S-A11Y-V34G-D36A.npz',\n",
       " 'nma/V7L-I48G-K74V-Q68Y-G62S.npz',\n",
       " 'nma/A56F.npz',\n",
       " 'nma/G27T-R38A-S70V.npz',\n",
       " 'nma/N13T-Y46R-A18Q.npz',\n",
       " 'nma/V61G-G1A-T25E-K73M-I48T.npz',\n",
       " 'nma/V22N.npz',\n",
       " 'nma/C14H.npz',\n",
       " 'nma/A72Q-I51F-V28F-L57W-Q4N.npz',\n",
       " 'nma/D29S.npz',\n",
       " 'nma/V69I-L2R-L67E-L21W.npz',\n",
       " 'nma/A64E-L53Q-K3S.npz',\n",
       " 'nma/S55L.npz',\n",
       " 'nma/I41G-K9Q-V34K-D49K.npz',\n",
       " 'nma/V61K.npz',\n",
       " 'nma/V10R-L53Y.npz',\n",
       " 'nma/K17G-A23C-L33S-D39C-D49S.npz',\n",
       " 'nma/V31M.npz',\n",
       " 'nma/A20H-G47L-Q4M-K52A.npz',\n",
       " 'nma/L2T-V10G-R38Q-V31L.npz',\n",
       " 'nma/A11S-E65N-Y46T-D49L-V69F.npz',\n",
       " 'nma/K3P-A72W-E65T-I41H.npz',\n",
       " 'nma/G35A-A23W-E65Q.npz',\n",
       " 'nma/A11Y-L57C-S24M-S55Y-M19S.npz',\n",
       " 'nma/S55Y.npz',\n",
       " 'nma/I51N-M19D-G26M-I41T-I8G.npz',\n",
       " 'nma/L33A.npz',\n",
       " 'nma/D63Q-A56D.npz',\n",
       " 'nma/D39P.npz',\n",
       " 'nma/G47R-S70P-K74L.npz',\n",
       " 'nma/D29Q-K9V-P50T.npz',\n",
       " 'nma/Q71T-E65S-L53G.npz',\n",
       " 'nma/D63V.npz',\n",
       " 'nma/I51V-V22R-E65W.npz',\n",
       " 'nma/S30G-Y46V-G27I.npz',\n",
       " 'nma/P50W-Q71I.npz',\n",
       " 'nma/Q68F-A11L-V61E-V31S-D36S.npz',\n",
       " 'nma/V69F.npz',\n",
       " 'nma/V69A-G45A-G1I.npz',\n",
       " 'nma/T25G-N13F-K9G-A72R.npz',\n",
       " 'nma/A64Q.npz',\n",
       " 'nma/L53V-K52I-R38S-V61H-I8V.npz',\n",
       " 'nma/D39C-L2E-M12D-K17A.npz',\n",
       " 'nma/Y46H-S30N-G27S-E42S.npz',\n",
       " 'nma/D29T.npz',\n",
       " 'nma/V31G-R38L-L37Y-A72G.npz',\n",
       " 'nma/K3A-G62S-G26W-G47P.npz',\n",
       " 'nma/K3R-R15K-N13W-I54Y.npz',\n",
       " 'nma/T25H.npz',\n",
       " 'nma/Y46G-L57Y-K73V.npz',\n",
       " 'nma/L67I.npz',\n",
       " 'nma/I48E.npz',\n",
       " 'nma/A11C-D63P-K73V-D39T-R15W.npz',\n",
       " 'nma/A64Y-L66G-S24C-D36K.npz',\n",
       " 'nma/G45F-I8P-E65C.npz',\n",
       " 'nma/G45L-A32N-V44S-Q71P-S55T.npz',\n",
       " 'nma/E65D-K40R-K3N.npz',\n",
       " 'nma/D39Y.npz',\n",
       " 'nma/I48W.npz',\n",
       " 'nma/A23E-G45P.npz',\n",
       " 'nma/L33Q-A23Q-G45L.npz',\n",
       " 'nma/K5V-S30W-Q68P-K59N.npz',\n",
       " 'nma/V69M.npz',\n",
       " 'nma/L33H-A64S-I41S-K3E-Q4I.npz',\n",
       " 'nma/N13A-Q4T-G26H-T25L-V69W.npz',\n",
       " 'nma/D49P-K52R-L33E-I51W.npz',\n",
       " 'nma/L66H-R38I.npz',\n",
       " 'nma/D29T-K73W.npz',\n",
       " 'nma/S30E-K3S-E42M.npz',\n",
       " 'nma/L53V-G35H-L57N.npz',\n",
       " 'nma/K9F-A56K-S70R.npz',\n",
       " 'nma/D63E-D29T-G62M-K3D-K60A.npz',\n",
       " 'nma/K59T.npz',\n",
       " 'nma/I8C-P50M-L2W.npz',\n",
       " 'nma/L66W-D63F-A18W-I51T.npz',\n",
       " 'nma/L66N-K40I-V31W-M19F.npz',\n",
       " 'nma/K9P-A11C-I54M.npz',\n",
       " 'nma/V43G.npz',\n",
       " 'nma/V34T-S30H.npz',\n",
       " 'nma/V7Q-T25L.npz',\n",
       " 'nma/V43M.npz',\n",
       " 'nma/I54C.npz',\n",
       " 'nma/K3P-G27P-S24E-G45V.npz',\n",
       " 'nma/P50H-R15Q-V34I-S55W-D36C.npz',\n",
       " 'nma/S16H.npz',\n",
       " 'nma/S24F-G26Y.npz',\n",
       " 'nma/P50F-T25A-L57F.npz',\n",
       " 'nma/G35E-I54K.npz',\n",
       " 'nma/V7P-V22M.npz',\n",
       " 'nma/D49F.npz',\n",
       " 'nma/K9S.npz',\n",
       " 'nma/V44P.npz',\n",
       " 'nma/A72D-V10P-N13T.npz',\n",
       " 'nma/S70R-G27Y.npz',\n",
       " 'nma/V22A-N13V.npz',\n",
       " 'nma/V28N-K5V-D49G-A56Y.npz',\n",
       " 'nma/D49H.npz',\n",
       " 'nma/S55P-A23F-L67D.npz',\n",
       " 'nma/I54W-G26V-K5M.npz',\n",
       " 'nma/Q4D-R58L.npz',\n",
       " 'nma/I54W-V69D-I41R-L2V-L53N.npz',\n",
       " 'nma/R58N-V44Q.npz',\n",
       " 'nma/M12K-Q68Y-L37S.npz',\n",
       " 'nma/S16N-R15Y-V34G-L21Y-V43D.npz',\n",
       " 'nma/D49K-V28E-G27V-S55R-R15Q.npz',\n",
       " 'nma/K60I.npz',\n",
       " 'nma/K59C-A11D.npz',\n",
       " 'nma/G62A.npz',\n",
       " 'nma/V69D-E42K-V31E-I48M-M19Y.npz',\n",
       " 'nma/V31K-V28I-K9Y-K17H-V34K.npz',\n",
       " 'nma/K40A-C14E-Q71R.npz',\n",
       " 'nma/I51C-K59V-D29T-V34Q.npz',\n",
       " 'nma/A72P.npz',\n",
       " 'nma/D29R-A32K-I41Q-S70P.npz',\n",
       " 'nma/K59N-Q71K-T25V-A11I-K5V.npz',\n",
       " 'nma/A18N-I6H-S24G.npz',\n",
       " 'nma/P50D-A32D-G47T-L66M.npz',\n",
       " 'nma/V34F-I6D-A23G.npz',\n",
       " 'nma/L21I.npz',\n",
       " 'nma/K73Y-D39E.npz']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mut_df = pd.read_csv('mutant_library/h1-c/mutant_library.csv')\n",
    "sequences = mut_df['sequence'].tolist()\n",
    "nma_paths = [f\"nma/{mut_string}.npz\" for mut_string in mut_df['mut']]\n",
    "\n",
    "nma_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "644d6f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # This section defines where your fine-tuned model and logs will be saved.\n",
    "    \"file_path\": {\n",
    "        \"save_dir\": \"models/esmdance-mutant-nma-fine-tuned/\", \n",
    "    },\n",
    "    \n",
    "    # General training settings.\n",
    "    \"training\": {\n",
    "        \"random_seed\": 42,\n",
    "        \"dropout\": 0.1,\n",
    "        \n",
    "        # You should adjust these based on how often you want to save and log.\n",
    "        # For a shorter fine-tuning run, you'll want to save more frequently.\n",
    "        \"save_per_epoch\": 1, # It's easier to think in epochs for fine-tuning.\n",
    "        \n",
    "        # --- Feature Indices ---\n",
    "        \"res_feature_idx\": {\n",
    "            'nma_residue1': [0],\n",
    "            'nma_residue2': [1],\n",
    "            'nma_residue3': [2],\n",
    "        },\n",
    "        \"pair_feature_idx\": {\n",
    "            'nma_pair1': [0],\n",
    "            'nma_pair2': [1],\n",
    "            'nma_pair3': [2],\n",
    "        },\n",
    "    },\n",
    "\n",
    "    \"esmdance\": {\n",
    "        \"freeze_esm\": True,      # Correct for ESMDance fine-tuning.\n",
    "        \"randomize_esm\": False,\n",
    "        \n",
    "        # All your sequences are 158, so we set one max_len.\n",
    "        # We add a little buffer, but it could be exactly 158.\n",
    "        \"max_len\": 256,\n",
    "        \n",
    "        # Define training by epochs, which is more intuitive for a fixed dataset.\n",
    "        \"num_epochs\": 20, # Adjust this based on how your loss behaves.\n",
    "        \n",
    "        # Set a single batch size. Adjust based on your GPU memory.\n",
    "        \"batch_size\": 4,\n",
    "        \n",
    "        # Gradient accumulation helps simulate a larger batch size.\n",
    "        # Effective batch size = batch_size * gradient_accumulation_steps\n",
    "        # Example: 8 * 4 = 32\n",
    "        \"gradient_accumulation_steps\": 4, \n",
    "    },\n",
    "\n",
    "    # Optimizer settings. These are generally good starting points.\n",
    "    \"optimizer\": {\n",
    "        \"peak_lr\": 1e-4,\n",
    "        \"epsilon\": 1e-8,\n",
    "        \"betas\": (0.9, 0.98),\n",
    "        \"weight_decay\": 0.01,\n",
    "        \"warmup_steps\": 200, # Number of steps for learning rate warmup.\n",
    "    },\n",
    "\n",
    "    # --- CRITICAL CHANGE 3: Model Output Dimensions ---\n",
    "    \"model_35M\": {\n",
    "        \"model_id\": \"facebook/esm2_t12_35M_UR50D\",\n",
    "        \"atten_dim\": 240,\n",
    "        \"embed_dim\": 480,\n",
    "        \n",
    "        # These now match your NMA-only data.\n",
    "        \"pair_out_dim\": 3, # Was 13. Now 3 for your 3 ANM correlation matrices.\n",
    "        \"res_out_dim\": 3,  # Was 50. Now 3 for your 3 GNM fluctuation vectors.\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ba844a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "full_dataset = FineTuneNMADataset(sequences, nma_paths)\n",
    "\n",
    "# Split data into training and validation sets (e.g., 90% train, 10% val)\n",
    "train_size = int(0.9 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=config['esmdance']['batch_size'], \n",
    "    shuffle=True, \n",
    "    collate_fn=collate_fn_nma\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config['esmdance']['batch_size'],\n",
    "    shuffle=False, # No need to shuffle validation data\n",
    "    collate_fn=collate_fn_nma\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09bcb66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import EsmModel\n",
    "from huggingface_hub import PyTorchModelHubMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ba370d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESMwrap(nn.Module, PyTorchModelHubMixin):\n",
    "    def __init__(self, esm2_select, model_select):\n",
    "        super().__init__()\n",
    "        # Load the ESM2 model\n",
    "        self.esm2 = EsmModel.from_pretrained(config[esm2_select]['model_id'])\n",
    "        self.freeze_esm = config[model_select]['freeze_esm']\n",
    "\n",
    "        # Freeze self.esm2 parameters if freeze_esm is True\n",
    "        if self.freeze_esm:\n",
    "            for param in self.esm2.parameters():\n",
    "                param.requires_grad = False\n",
    "            self.esm2.eval()  # Set to evaluation mode\n",
    "\n",
    "        # Randomize self.esm2 parameters if randomize_esm is True\n",
    "        if config[model_select]['randomize_esm']:\n",
    "            self.randomize_model(self.esm2)\n",
    "\n",
    "        # dimensions of input and output\n",
    "        embed_dim = config[esm2_select]['embed_dim']\n",
    "        res_out_dim = config[esm2_select]['res_out_dim']\n",
    "        atten_dim = config[esm2_select]['atten_dim']\n",
    "        pair_out_dim = config[esm2_select]['pair_out_dim']\n",
    "\n",
    "        # Residue-level prediction layer\n",
    "        self.res_pred_nn = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm(embed_dim),\n",
    "            nn.Dropout(config['training']['dropout']),  # Apply dropout after LayerNorm\n",
    "            nn.Linear(embed_dim, res_out_dim)\n",
    "        )\n",
    "\n",
    "        # transform res embedding for Pairwise prediction\n",
    "        self.res_transform_nn = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm(embed_dim),\n",
    "            nn.Dropout(config['training']['dropout']),  # Apply dropout after LayerNorm\n",
    "            nn.Linear(embed_dim, embed_dim*2)\n",
    "        )\n",
    "\n",
    "        # Pairwise prediction layer\n",
    "        self.pair_middle_linear = nn.Linear(embed_dim*2, atten_dim)\n",
    "        self.pair_pred_linear = nn.Linear(atten_dim + atten_dim, pair_out_dim)\n",
    "\n",
    "        # Activation functions\n",
    "        self.gelu = nn.GELU()\n",
    "        self.softplus = nn.Softplus(beta=1.0, threshold=2.0)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "        # Feature indices from config\n",
    "        self.res_feature_idx = config['training']['res_feature_idx']\n",
    "        self.pair_feature_idx = config['training']['pair_feature_idx']\n",
    "\n",
    "        # Initialize biases to zero\n",
    "        self._init_bias_zero()\n",
    "\n",
    "    def randomize_model(self, model):\n",
    "        \"\"\" Randomize the parameters of the given model. \"\"\"\n",
    "        for module_ in model.named_modules():\n",
    "            if isinstance(module_[1], (torch.nn.Linear, torch.nn.Embedding)):\n",
    "                if hasattr(module_[1], 'bias') and module_[1].bias is not None:\n",
    "                    module_[1].bias.data.zero_()\n",
    "                if hasattr(module_[1], 'weight'):\n",
    "                    if 'query' in module_[0] or 'key' in module_[0] or 'value' in module_[0]:\n",
    "                        module_[1].weight = nn.init.xavier_uniform_(module_[1].weight, gain=1 / math.sqrt(2))\n",
    "                    else:\n",
    "                        module_[1].weight = nn.init.xavier_uniform_(module_[1].weight)\n",
    "                            \n",
    "            elif isinstance(module_[1], nn.LayerNorm):\n",
    "                if hasattr(module_[1], 'bias'):\n",
    "                    module_[1].bias.data.zero_()\n",
    "                if hasattr(module_[1], 'weight'):\n",
    "                    module_[1].weight.data.fill_(1.0)\n",
    "                \n",
    "            elif isinstance(module_[1], nn.Dropout):\n",
    "                module_[1].p = config['training']['dropout']\n",
    "\n",
    "\n",
    "    def _init_bias_zero(self):\n",
    "        \"\"\" Set all biases in the model (excluding esm2) to zero. \"\"\"\n",
    "        for name, module in self.named_modules():\n",
    "            if \"esm2\" not in name and isinstance(module, nn.Linear) and module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "\n",
    "\n",
    "    def forward(self, inputs, return_res_emb=False, return_attention_map=False, return_res_pred=True, return_pair_pred=True):\n",
    "        output = {}\n",
    "\n",
    "        # ESM forward pass, Ensure no gradients are stored for frozen ESM2\n",
    "        if self.freeze_esm:\n",
    "            with torch.no_grad():\n",
    "                esm_output = self.esm2(**inputs, output_attentions=True)\n",
    "        else:\n",
    "            esm_output = self.esm2(**inputs, output_attentions=True)\n",
    "\n",
    "        res_emb = esm_output['last_hidden_state']\n",
    "        pair_atten = torch.cat(esm_output['attentions'], dim=1).permute(0, 2, 3, 1)\n",
    "\n",
    "        if return_res_emb:\n",
    "            output['res_emb'] = res_emb\n",
    "        if return_attention_map:\n",
    "            output['attention_map'] = pair_atten\n",
    "\n",
    "        # Residue-level prediction\n",
    "        if return_res_pred:\n",
    "            res_pred = self.res_pred_nn(res_emb)\n",
    "            for feature in self.res_feature_idx:\n",
    "                if feature == 'rmsf_nor':\n",
    "                    # Normalized RMSF (max = 1)\n",
    "                    output[feature] = self.sigmoid(res_pred[:, :, self.res_feature_idx[feature]])\n",
    "                elif feature in ['ss', 'chi', 'phi', 'psi']:\n",
    "                    # Secondary structure, chi, phi, psi sum up to 1\n",
    "                    output[feature] = self.softmax(res_pred[:, :, self.res_feature_idx[feature]])\n",
    "                else:\n",
    "                    # All other features are non-negative\n",
    "                    output[feature] = self.softplus(res_pred[:, :, self.res_feature_idx[feature]])\n",
    "\n",
    "        # Pairwise transformation\n",
    "        s = self.res_transform_nn(res_emb)\n",
    "        q, k = s.chunk(2, dim=-1)\n",
    "        prod = q[:, None, :, :] * k[:, :, None, :]\n",
    "        diff = q[:, None, :, :] - k[:, :, None, :]\n",
    "        pair_middle = self.gelu(self.pair_middle_linear(torch.cat([prod, diff], dim=-1)))\n",
    "\n",
    "        # Pairwise prediction\n",
    "        if return_pair_pred:\n",
    "            pair_pred = self.pair_pred_linear(torch.cat([pair_middle, pair_atten], dim=-1))\n",
    "\n",
    "            for feature in self.pair_feature_idx:\n",
    "                if feature in ['corr', 'nma_pair1', 'nma_pair2', 'nma_pair3']:\n",
    "                    # Co-movement and NMA co-movement correlations: range [-1, 1]\n",
    "                    output[feature] = self.sigmoid(pair_pred[:, :, :, self.pair_feature_idx[feature]]) * 2 - 1.0\n",
    "                else:\n",
    "                    # All interaction features are non-negative\n",
    "                    output[feature] = self.softplus(pair_pred[:, :, :, self.pair_feature_idx[feature]])\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e73d2f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97759489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(config['training']['random_seed'])\n",
    "np.random.seed(config['training']['random_seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3132fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "# Create save directory from config\n",
    "save_dir = Path(config['file_path']['save_dir'])\n",
    "save_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "710ac295",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t12_35M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = ESMwrap(esm2_select='model_35M', model_select='esmdance').to(device)\n",
    "checkpoint = torch.load('pretrained_weights/esmdance_update_60000.pt')\n",
    "model_state_dict = model.state_dict()\n",
    "\n",
    "filtered_state_dict = {\n",
    "            k: v for k, v in checkpoint.items() \n",
    "            if k in model_state_dict and v.shape == model_state_dict[k].shape\n",
    "        }\n",
    "        \n",
    "# Update our new model's state dict with the filtered weights\n",
    "model_state_dict.update(filtered_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4841bbaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(model_state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0c9b501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===========================================================================================================================================================\n",
       "Layer (type (var_name))                                                     Input Shape          Output Shape         Param #              Trainable\n",
       "===========================================================================================================================================================\n",
       "ESMwrap (ESMwrap)                                                           [1, 160]             [1, 160, 160, 1]     --                   Partial\n",
       "├─EsmModel (esm2)                                                           --                   [1, 20, 160, 160]    241                  False\n",
       "│    └─EsmEmbeddings (embeddings)                                           --                   [1, 160, 480]        492,480              False\n",
       "│    │    └─Embedding (word_embeddings)                                     [1, 160]             [1, 160, 480]        (15,840)             False\n",
       "│    └─EsmEncoder (encoder)                                                 [1, 160, 480]        [1, 20, 160, 160]    --                   False\n",
       "│    │    └─ModuleList (layer)                                              --                   --                   (33,252,480)         False\n",
       "│    │    └─LayerNorm (emb_layer_norm_after)                                [1, 160, 480]        [1, 160, 480]        (960)                False\n",
       "│    └─EsmPooler (pooler)                                                   [1, 160, 480]        [1, 480]             --                   False\n",
       "│    │    └─Linear (dense)                                                  [1, 480]             [1, 480]             (230,880)            False\n",
       "│    │    └─Tanh (activation)                                               [1, 480]             [1, 480]             --                   --\n",
       "├─Sequential (res_pred_nn)                                                  [1, 160, 480]        [1, 160, 3]          --                   True\n",
       "│    └─Linear (0)                                                           [1, 160, 480]        [1, 160, 480]        230,880              True\n",
       "│    └─GELU (1)                                                             [1, 160, 480]        [1, 160, 480]        --                   --\n",
       "│    └─LayerNorm (2)                                                        [1, 160, 480]        [1, 160, 480]        960                  True\n",
       "│    └─Dropout (3)                                                          [1, 160, 480]        [1, 160, 480]        --                   --\n",
       "│    └─Linear (4)                                                           [1, 160, 480]        [1, 160, 3]          1,443                True\n",
       "├─Softplus (softplus)                                                       [1, 160, 1]          [1, 160, 1]          --                   --\n",
       "├─Softplus (softplus)                                                       [1, 160, 1]          [1, 160, 1]          --                   --\n",
       "├─Softplus (softplus)                                                       [1, 160, 1]          [1, 160, 1]          --                   --\n",
       "├─Sequential (res_transform_nn)                                             [1, 160, 480]        [1, 160, 960]        --                   True\n",
       "│    └─Linear (0)                                                           [1, 160, 480]        [1, 160, 480]        230,880              True\n",
       "│    └─GELU (1)                                                             [1, 160, 480]        [1, 160, 480]        --                   --\n",
       "│    └─LayerNorm (2)                                                        [1, 160, 480]        [1, 160, 480]        960                  True\n",
       "│    └─Dropout (3)                                                          [1, 160, 480]        [1, 160, 480]        --                   --\n",
       "│    └─Linear (4)                                                           [1, 160, 480]        [1, 160, 960]        461,760              True\n",
       "├─Linear (pair_middle_linear)                                               [1, 160, 160, 960]   [1, 160, 160, 240]   230,640              True\n",
       "├─GELU (gelu)                                                               [1, 160, 160, 240]   [1, 160, 160, 240]   --                   --\n",
       "├─Linear (pair_pred_linear)                                                 [1, 160, 160, 480]   [1, 160, 160, 3]     1,443                True\n",
       "├─Sigmoid (sigmoid)                                                         [1, 160, 160, 1]     [1, 160, 160, 1]     --                   --\n",
       "├─Sigmoid (sigmoid)                                                         [1, 160, 160, 1]     [1, 160, 160, 1]     --                   --\n",
       "├─Sigmoid (sigmoid)                                                         [1, 160, 160, 1]     [1, 160, 160, 1]     --                   --\n",
       "===========================================================================================================================================================\n",
       "Total params: 35,151,847\n",
       "Trainable params: 1,158,966\n",
       "Non-trainable params: 33,992,881\n",
       "Total mult-adds (Units.MEGABYTES): 34.66\n",
       "===========================================================================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 135.79\n",
       "Params size (MB): 138.64\n",
       "Estimated Total Size (MB): 274.43\n",
       "==========================================================================================================================================================="
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "batch_size = 1\n",
    "sequence_length = 160 # 158 residues + 2 special tokens\n",
    "\n",
    "dummy_input_ids = torch.randint(0, 33, (batch_size, sequence_length), dtype=torch.long)\n",
    "dummy_attention_mask = torch.ones(batch_size, sequence_length, dtype=torch.long)\n",
    "\n",
    "dummy_inputs_dict = {\n",
    "    \"input_ids\": dummy_input_ids,\n",
    "    \"attention_mask\": dummy_attention_mask\n",
    "}\n",
    "\n",
    "# This tells torchinfo to pass the dictionary as a single positional argument,\n",
    "# which matches your model's forward(self, inputs) signature.\n",
    "input_data_for_summary = (dummy_inputs_dict,)\n",
    "\n",
    "summary(\n",
    "    model,\n",
    "    # Pass the TUPLE containing the dictionary\n",
    "    input_data=input_data_for_summary,\n",
    "    \n",
    "    # The other summary arguments are for torchinfo itself and will no longer be passed to your model\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "    col_width=20,\n",
    "    row_settings=[\"var_names\"],\n",
    "    device=\"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "864bbd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 1,158,966\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.amp import GradScaler, autocast\n",
    "\n",
    "loss_function = nn.MSELoss(reduction='none') # Use reduction='none' for custom masking\n",
    "trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "print(f\"Total trainable parameters: {sum(p.numel() for p in trainable_params):,}\")\n",
    "optimizer = AdamW(trainable_params, lr=config['optimizer']['peak_lr'], betas=config['optimizer']['betas'])\n",
    "\n",
    "scaler = GradScaler() # For mixed-precision training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c66bc808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fine-tuning for 20 epochs...\n",
      "\n",
      "Epoch 1/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 [Training]: 100%|██████████| 68/68 [00:06<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.0352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 22.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4626\n",
      "\n",
      "Epoch 2/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 15.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 22.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2625\n",
      "\n",
      "Epoch 3/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 15.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 20.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1970\n",
      "\n",
      "Epoch 4/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 15.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 23.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1592\n",
      "\n",
      "Epoch 5/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 [Training]: 100%|██████████| 68/68 [00:01<00:00, 42.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 18.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1296\n",
      "\n",
      "Epoch 6/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 15.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 23.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1063\n",
      "\n",
      "Epoch 7/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 15.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 23.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0881\n",
      "\n",
      "Epoch 8/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 15.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 23.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0740\n",
      "\n",
      "Epoch 9/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 15.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 21.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0632\n",
      "\n",
      "Epoch 10/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 15.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 23.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0549\n",
      "\n",
      "Epoch 11/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 15.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 22.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0482\n",
      "\n",
      "Epoch 12/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 [Training]: 100%|██████████| 68/68 [00:01<00:00, 53.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 24.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0429\n",
      "\n",
      "Epoch 13/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 15.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 23.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0383\n",
      "\n",
      "Epoch 14/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 15.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 23.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0348\n",
      "\n",
      "Epoch 15/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 15.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 22.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0316\n",
      "\n",
      "Epoch 16/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 15.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 21.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0292\n",
      "\n",
      "Epoch 17/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 15.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 24.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0267\n",
      "\n",
      "Epoch 18/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 15.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 22.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0249\n",
      "\n",
      "Epoch 19/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 [Training]: 100%|██████████| 68/68 [00:01<00:00, 44.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 21.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0233\n",
      "\n",
      "Epoch 20/20\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 [Training]: 100%|██████████| 68/68 [00:04<00:00, 15.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 [Validation]: 100%|██████████| 8/8 [00:00<00:00, 22.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.amp import autocast\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = config['esmdance']['num_epochs']\n",
    "grad_accum_steps = config['esmdance']['gradient_accumulation_steps']\n",
    "\n",
    "print(f\"Starting fine-tuning for {num_epochs} epochs...\")\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'\\nEpoch {epoch+1}/{num_epochs}\\n------------------------------')\n",
    "    # =======================================\n",
    "    #               TRAINING\n",
    "    # =======================================\n",
    "    model.train() # Set the model to training mode\n",
    "    total_train_loss = 0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} [Training]\")):\n",
    "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "        labels = {key: val.to(device) for key, val in labels.items()}\n",
    "        \n",
    "        with autocast(device_type='cuda', dtype=torch.float16):\n",
    "            predictions = model(inputs)\n",
    "            \n",
    "            # --- Loss Calculation ---\n",
    "            res_loss = 0\n",
    "            res_mask = labels['nma_residue1'] != -1\n",
    "            for k in ['nma_residue1', 'nma_residue2', 'nma_residue3']:\n",
    "                pred_k = predictions[k].squeeze(-1)\n",
    "                label_k = labels[k]\n",
    "                element_wise_loss = loss_function(pred_k, label_k)\n",
    "                valid_losses = element_wise_loss[res_mask]\n",
    "                res_loss += valid_losses.mean()\n",
    "\n",
    "            pair_loss = 0\n",
    "            pair_mask = labels['nma_pair1'] != -1\n",
    "            for k in ['nma_pair1', 'nma_pair2', 'nma_pair3']:\n",
    "                pred_pair_k = predictions[k].squeeze(-1)\n",
    "                label_pair_k = labels[k]\n",
    "                element_wise_loss = loss_function(pred_pair_k, label_pair_k)\n",
    "                valid_losses = element_wise_loss[pair_mask]\n",
    "                pair_loss += valid_losses.mean()\n",
    "            \n",
    "            loss = (3 * pair_loss + res_loss) / grad_accum_steps\n",
    "        \n",
    "        # --- Gradient Accumulation & Backpropagation ---\n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        if (i + 1) % grad_accum_steps == 0 or (i + 1) == len(train_loader):\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        total_train_loss += loss.item() * grad_accum_steps\n",
    "        \n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    print(f\"Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # =======================================\n",
    "    #              VALIDATION\n",
    "    # =======================================\n",
    "    model.eval() # Set the model to evaluation mode\n",
    "    total_val_loss = 0\n",
    "    \n",
    "    # Disable gradient calculations for validation to save memory and compute\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} [Validation]\")):\n",
    "            inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "            labels = {key: val.to(device) for key, val in labels.items()}\n",
    "            \n",
    "            # Forward pass only, still use autocast for consistency\n",
    "            with autocast(device_type='cuda', dtype=torch.float16):\n",
    "                predictions = model(inputs)\n",
    "\n",
    "                # --- Loss Calculation (Identical to training) ---\n",
    "                res_loss = 0\n",
    "                res_mask = labels['nma_residue1'] != -1\n",
    "                for k in ['nma_residue1', 'nma_residue2', 'nma_residue3']:\n",
    "                    pred_k = predictions[k].squeeze(-1)\n",
    "                    label_k = labels[k]\n",
    "                    element_wise_loss = loss_function(pred_k, label_k)\n",
    "                    valid_losses = element_wise_loss[res_mask]\n",
    "                    res_loss += valid_losses.mean()\n",
    "\n",
    "                pair_loss = 0\n",
    "                pair_mask = labels['nma_pair1'] != -1\n",
    "                for k in ['nma_pair1', 'nma_pair2', 'nma_pair3']:\n",
    "                    pred_pair_k = predictions[k].squeeze(-1)\n",
    "                    label_pair_k = labels[k]\n",
    "                    element_wise_loss = loss_function(pred_pair_k, label_pair_k)\n",
    "                    valid_losses = element_wise_loss[pair_mask]\n",
    "                    pair_loss += valid_losses.mean()\n",
    "                \n",
    "                # Note: We do NOT divide by grad_accum_steps for validation loss\n",
    "                val_loss = 3 * pair_loss + res_loss\n",
    "            \n",
    "            total_val_loss += val_loss.item()\n",
    "            \n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4802d3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = save_dir / \"esmdance_fine-tuned_with_nma_data.pth\"\n",
    "torch.save(model.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e20c17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
