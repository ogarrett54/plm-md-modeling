{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83fbb22c",
   "metadata": {},
   "source": [
    "# Baseline Fine-tuning For Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1383be8f",
   "metadata": {},
   "source": [
    "## Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6965bffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4fcc868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa_sequence</th>\n",
       "      <th>enrichment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GLKQKIVIKVAMEGNNCRSKAMALVASTGGVDSVALVGDLRDKIEV...</td>\n",
       "      <td>1.468796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GLKRIIVIKVAREGNNCRSKAMALVASTGGVDSVALVGDLRGKIEV...</td>\n",
       "      <td>1.415944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GLKRIIVIKVAMEGNNCRSKAMALVASTGGVDSVALVGDLRGKIEV...</td>\n",
       "      <td>1.389615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GLKQKIVIKVAMEGNNCRSKAMALVASTGGVDSVALVGDLRDKIEV...</td>\n",
       "      <td>1.359651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GLKQKIVIKVAMEGNNCRSKAMALVASTGGVDSVALVGDLRGKIEV...</td>\n",
       "      <td>1.343857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3955</th>\n",
       "      <td>GLKQKIVIKVAMEGNNCRSKAMALVASTGGVDSVALVGDLRDKIEV...</td>\n",
       "      <td>-1.041749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3956</th>\n",
       "      <td>GLKQKIVIKVAMEGNNCRSKAMALVASTGGVDSVALVGDLRDKIEA...</td>\n",
       "      <td>-1.041749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3957</th>\n",
       "      <td>GLKQKIVIKVAMEGNNCRSKAMALVASTGGVDSVALVGDLRDKIEV...</td>\n",
       "      <td>-1.057543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3958</th>\n",
       "      <td>GLKQKIVIKVAMEGNNCRSKAMALVASTGGVDSVALVGDLRDKTEV...</td>\n",
       "      <td>-1.057543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3959</th>\n",
       "      <td>GLKQKIVIKVAMEGNNCRSKAMALVASTGGVDSVALVGDLRDKTEV...</td>\n",
       "      <td>-1.057543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3960 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            aa_sequence  enrichment_score\n",
       "0     GLKQKIVIKVAMEGNNCRSKAMALVASTGGVDSVALVGDLRDKIEV...          1.468796\n",
       "1     GLKRIIVIKVAREGNNCRSKAMALVASTGGVDSVALVGDLRGKIEV...          1.415944\n",
       "2     GLKRIIVIKVAMEGNNCRSKAMALVASTGGVDSVALVGDLRGKIEV...          1.389615\n",
       "3     GLKQKIVIKVAMEGNNCRSKAMALVASTGGVDSVALVGDLRDKIEV...          1.359651\n",
       "4     GLKQKIVIKVAMEGNNCRSKAMALVASTGGVDSVALVGDLRGKIEV...          1.343857\n",
       "...                                                 ...               ...\n",
       "3955  GLKQKIVIKVAMEGNNCRSKAMALVASTGGVDSVALVGDLRDKIEV...         -1.041749\n",
       "3956  GLKQKIVIKVAMEGNNCRSKAMALVASTGGVDSVALVGDLRDKIEA...         -1.041749\n",
       "3957  GLKQKIVIKVAMEGNNCRSKAMALVASTGGVDSVALVGDLRDKIEV...         -1.057543\n",
       "3958  GLKQKIVIKVAMEGNNCRSKAMALVASTGGVDSVALVGDLRDKTEV...         -1.057543\n",
       "3959  GLKQKIVIKVAMEGNNCRSKAMALVASTGGVDSVALVGDLRDKTEV...         -1.057543\n",
       "\n",
       "[3960 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dir = Path('yeast_data')\n",
    "df = pd.read_csv(str(input_dir / 'avrpikC_full.csv'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1819a163",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BindingDataset(Dataset):\n",
    "    \"\"\"Dataset for the final binding prediction task.\"\"\"\n",
    "    def __init__(self, dataframe):\n",
    "        self.df = dataframe\n",
    "        # Ensure the columns exist\n",
    "        assert 'aa_sequence' in self.df.columns, \"DataFrame must have 'aa_sequence' column.\"\n",
    "        assert 'enrichment_score' in self.df.columns, \"DataFrame must have 'enrichment_score' column.\"\n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t12_35M_UR50D\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.df.iloc[idx]['aa_sequence']\n",
    "        # The label is a single float value\n",
    "        label = torch.tensor(self.df.iloc[idx]['enrichment_score'], dtype=torch.float)\n",
    "\n",
    "        # Tokenize the sequence\n",
    "        tokenized_output = self.tokenizer(\n",
    "            sequence,\n",
    "            max_length=160, # Use a fixed max length. 158 residues plus 2 extra tokens\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Return input_ids: attention masks, removing batch dimension\n",
    "        inputs = {key: val.squeeze(0) for key, val in tokenized_output.items()}\n",
    "        \n",
    "        return inputs, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db1725b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = BindingDataset(df)\n",
    "\n",
    "train_size = int(0.9 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc93c71",
   "metadata": {},
   "source": [
    "## Baseline 1: Fine-tuning the full ESM2 8M model\n",
    "This is the default method that Alexander used, though he used the huggingface transformer library, so results are slightly different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ae2928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Initializing ESM-2 35M for Sequence Classification...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmForSequenceClassification were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 7,840,442\n",
      "Starting fine-tuning for 5 epochs...\n",
      "\n",
      "Epoch 1/5\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 223/223 [00:11<00:00, 18.69it/s]\n",
      "[Validation]: 100%|██████████| 25/25 [00:00<00:00, 55.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1978 | Validation Loss: 0.1723 | Spearman Correlation: 0.5596\n",
      "\n",
      "Epoch 2/5\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 223/223 [00:14<00:00, 15.11it/s]\n",
      "[Validation]: 100%|██████████| 25/25 [00:00<00:00, 41.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1420 | Validation Loss: 0.1197 | Spearman Correlation: 0.6244\n",
      "\n",
      "Epoch 3/5\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 223/223 [00:11<00:00, 19.16it/s]\n",
      "[Validation]: 100%|██████████| 25/25 [00:00<00:00, 52.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1210 | Validation Loss: 0.1192 | Spearman Correlation: 0.6939\n",
      "\n",
      "Epoch 4/5\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 223/223 [00:15<00:00, 14.38it/s]\n",
      "[Validation]: 100%|██████████| 25/25 [00:00<00:00, 33.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1044 | Validation Loss: 0.0923 | Spearman Correlation: 0.7229\n",
      "\n",
      "Epoch 5/5\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 223/223 [00:18<00:00, 11.80it/s]\n",
      "[Validation]: 100%|██████████| 25/25 [00:00<00:00, 48.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0966 | Validation Loss: 0.0859 | Spearman Correlation: 0.7586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from transformers import EsmForSequenceClassification\n",
    "from scipy.stats import spearmanr\n",
    "import tqdm\n",
    "\n",
    "# --- SETUP ---\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- MODEL INITIALIZATION ---\n",
    "print(\"Initializing ESM-2 8M for Sequence Classification...\")\n",
    "\n",
    "model = EsmForSequenceClassification.from_pretrained(\n",
    "    \"facebook/esm2_t6_8M_UR50D\",\n",
    "    num_labels=1,                # We are predicting one continuous value.\n",
    "    problem_type=\"regression\"    # Configure the model for regression.\n",
    ").to(device)\n",
    "\n",
    "# --- LOSS AND OPTIMIZER ---\n",
    "# We will let the model calculate its own loss during training, but define it for validation\n",
    "loss_function = nn.MSELoss() \n",
    "\n",
    "# The optimizer will automatically ignore frozen parameters\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Count trainable parameters to confirm the base is frozen\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# --- TRAINING & VALIDATION LOOP ---\n",
    "num_epochs = 5\n",
    "print(f\"Starting fine-tuning for {num_epochs} epochs...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'\\nEpoch {epoch + 1}/{num_epochs}\\n----------------------------')\n",
    "    # =======================================\n",
    "    #               TRAINING\n",
    "    # =======================================\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"[Training]\"):\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # The model automatically calculates loss when labels are provided\n",
    "        outputs = model(**inputs, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_train_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    \n",
    "    # =======================================\n",
    "    #              VALIDATION\n",
    "    # =======================================\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    epoch_predictions = []\n",
    "    epoch_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(val_loader, desc=f\"[Validation]\"):\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Get model predictions (logits)\n",
    "            outputs = model(**inputs)\n",
    "            predictions = outputs.logits\n",
    "            \n",
    "            # Calculate validation loss manually\n",
    "            total_val_loss += loss_function(predictions.squeeze(), labels).item()\n",
    "            \n",
    "            # Collect predictions and labels for Spearman correlation\n",
    "            epoch_predictions.append(predictions.cpu())\n",
    "            epoch_labels.append(labels.cpu())\n",
    "    \n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    \n",
    "    # Calculate Spearman Correlation\n",
    "    all_predictions = torch.cat(epoch_predictions).numpy().flatten()\n",
    "    all_labels = torch.cat(epoch_labels).numpy().flatten()\n",
    "    spearman_corr, p_value = spearmanr(all_predictions, all_labels)\n",
    "    \n",
    "    print(f\"Training Loss: {avg_train_loss:.4f} | Validation Loss: {avg_val_loss:.4f} | Spearman Correlation: {spearman_corr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129efa53",
   "metadata": {},
   "source": [
    "## Baseline 2: 35M ESM2-only feature extractor\n",
    "For a simple comparison, what happens when you only use ESM2 as the feature extractor for the binding head above. This uses the special class token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93115291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Initializing ESM-2 35M for Sequence Classification...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmForSequenceClassification were not initialized from the model checkpoint at facebook/esm2_t12_35M_UR50D and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing the ESM-2 base model layers...\n",
      "Total trainable parameters: 231,361\n",
      "Starting fine-tuning for 5 epochs...\n",
      "\n",
      "Epoch 1/5\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train]: 100%|██████████| 223/223 [00:05<00:00, 37.48it/s] \n",
      "[Val]: 100%|██████████| 25/25 [00:00<00:00, 29.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2091 | Validation Loss: 0.1943 | Spearman Correlation: 0.5128\n",
      "\n",
      "Epoch 2/5\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train]: 100%|██████████| 223/223 [00:08<00:00, 26.61it/s]\n",
      "[Val]: 100%|██████████| 25/25 [00:00<00:00, 26.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2015 | Validation Loss: 0.1979 | Spearman Correlation: 0.5311\n",
      "\n",
      "Epoch 3/5\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train]: 100%|██████████| 223/223 [00:08<00:00, 27.20it/s]\n",
      "[Val]: 100%|██████████| 25/25 [00:00<00:00, 25.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1930 | Validation Loss: 0.1779 | Spearman Correlation: 0.5412\n",
      "\n",
      "Epoch 4/5\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train]: 100%|██████████| 223/223 [00:05<00:00, 42.07it/s]\n",
      "[Val]: 100%|██████████| 25/25 [00:00<00:00, 28.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1841 | Validation Loss: 0.1641 | Spearman Correlation: 0.5499\n",
      "\n",
      "Epoch 5/5\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train]: 100%|██████████| 223/223 [00:08<00:00, 27.57it/s]\n",
      "[Val]: 100%|██████████| 25/25 [00:00<00:00, 26.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1734 | Validation Loss: 0.1513 | Spearman Correlation: 0.5563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from transformers import AutoTokenizer, EsmForSequenceClassification\n",
    "import tqdm\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "\n",
    "# --- SETUP ---\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- MODEL INITIALIZATION ---\n",
    "print(\"Initializing ESM-2 35M for Sequence Classification...\")\n",
    "\n",
    "model = EsmForSequenceClassification.from_pretrained(\n",
    "    \"facebook/esm2_t12_35M_UR50D\",\n",
    "    num_labels=1,                # We are predicting one continuous value.\n",
    "    problem_type=\"regression\"    # Configure the model for regression.\n",
    ").to(device)\n",
    "\n",
    "# --- FREEZE THE BASE MODEL (for fair comparison) ---\n",
    "print(\"Freezing the ESM-2 base model layers...\")\n",
    "for name, param in model.named_parameters():\n",
    "    if name.startswith(\"esm.\"): # This freezes all parameters of the main ESM body\n",
    "        param.requires_grad = False\n",
    "\n",
    "# --- LOSS AND OPTIMIZER ---\n",
    "# We will let the model calculate its own loss during training, but define it for validation\n",
    "loss_function = nn.MSELoss() \n",
    "\n",
    "# The optimizer will automatically ignore frozen parameters\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Count trainable parameters to confirm the base is frozen\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# --- TRAINING & VALIDATION LOOP ---\n",
    "num_epochs = 5\n",
    "print(f\"Starting fine-tuning for {num_epochs} epochs...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'\\nEpoch {epoch + 1}/{num_epochs}\\n----------------------------')\n",
    "    # =======================================\n",
    "    #               TRAINING\n",
    "    # =======================================\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"[Training]\"):\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # The model automatically calculates loss when labels are provided\n",
    "        outputs = model(**inputs, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_train_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    \n",
    "    # =======================================\n",
    "    #              VALIDATION\n",
    "    # =======================================\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    epoch_predictions = []\n",
    "    epoch_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(val_loader, desc=f\"[Validation]\"):\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Get model predictions (logits)\n",
    "            outputs = model(**inputs)\n",
    "            predictions = outputs.logits\n",
    "            \n",
    "            # Calculate validation loss manually\n",
    "            total_val_loss += loss_function(predictions.squeeze(), labels).item()\n",
    "            \n",
    "            # Collect predictions and labels for Spearman correlation\n",
    "            epoch_predictions.append(predictions.cpu())\n",
    "            epoch_labels.append(labels.cpu())\n",
    "    \n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    \n",
    "    # Calculate Spearman Correlation\n",
    "    all_predictions = torch.cat(epoch_predictions).numpy().flatten()\n",
    "    all_labels = torch.cat(epoch_labels).numpy().flatten()\n",
    "    spearman_corr, p_value = spearmanr(all_predictions, all_labels)\n",
    "    \n",
    "    print(f\"Training Loss: {avg_train_loss:.4f} | Validation Loss: {avg_val_loss:.4f} | Spearman Correlation: {spearman_corr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc4c2b7",
   "metadata": {},
   "source": [
    "## Baseline 3: 35M ESM2 Model with Last Two Layers Unfrozen\n",
    "This is to test another strategy for fine-tuning that was detailed in the ESMEffect paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1de85aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Initializing ESM-2 35M for Sequence Classification...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmForSequenceClassification were not initialized from the model checkpoint at facebook/esm2_t12_35M_UR50D and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing the ESM-2 base model and unfreezing the final 2 layers...\n",
      "Total trainable parameters: 5,773,441\n",
      "Starting fine-tuning for 5 epochs...\n",
      "\n",
      "Epoch 1/5\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 223/223 [00:13<00:00, 16.42it/s]\n",
      "[Validation]: 100%|██████████| 25/25 [00:01<00:00, 19.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1906 | Validation Loss: 0.1245 | Spearman Correlation: 0.6330\n",
      "\n",
      "Epoch 2/5\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 223/223 [00:11<00:00, 18.79it/s]\n",
      "[Validation]: 100%|██████████| 25/25 [00:00<00:00, 30.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1268 | Validation Loss: 0.1068 | Spearman Correlation: 0.7100\n",
      "\n",
      "Epoch 3/5\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 223/223 [00:10<00:00, 20.96it/s]\n",
      "[Validation]: 100%|██████████| 25/25 [00:00<00:00, 28.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1140 | Validation Loss: 0.0906 | Spearman Correlation: 0.7507\n",
      "\n",
      "Epoch 4/5\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 223/223 [00:08<00:00, 27.46it/s] \n",
      "[Validation]: 100%|██████████| 25/25 [00:00<00:00, 25.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1022 | Validation Loss: 0.0885 | Spearman Correlation: 0.7503\n",
      "\n",
      "Epoch 5/5\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 223/223 [00:10<00:00, 20.68it/s]\n",
      "[Validation]: 100%|██████████| 25/25 [00:00<00:00, 28.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0930 | Validation Loss: 0.1062 | Spearman Correlation: 0.7602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, EsmForSequenceClassification\n",
    "\n",
    "# --- SETUP ---\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- MODEL INITIALIZATION ---\n",
    "print(\"Initializing ESM-2 35M for Sequence Classification...\")\n",
    "\n",
    "model = EsmForSequenceClassification.from_pretrained(\n",
    "    \"facebook/esm2_t12_35M_UR50D\",\n",
    "    num_labels=1,                # We are predicting one continuous value.\n",
    "    problem_type=\"regression\"    # Configure the model for regression.\n",
    ").to(device)\n",
    "\n",
    "# FREEZE THE BASE, UNFREEZE LAST TWO LAYERS ---\n",
    "print(\"Freezing the ESM-2 base model and unfreezing the final 2 layers...\")\n",
    "\n",
    "# 1. First, freeze all parameters of the entire base model\n",
    "for param in model.esm.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 2. Now, unfreeze only the parameters of the last two transformer layers\n",
    "# The ESM-2 35M model has 12 layers (0-11) in model.esm.encoder.layer\n",
    "num_layers_to_unfreeze = 2\n",
    "for layer in model.esm.encoder.layer[-num_layers_to_unfreeze:]:\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "# --- LOSS AND OPTIMIZER ---\n",
    "# We will let the model calculate its own loss during training, but define it for validation\n",
    "loss_function = nn.MSELoss() \n",
    "\n",
    "# The optimizer will automatically ignore frozen parameters\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Count trainable parameters to confirm the base is frozen\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# --- TRAINING & VALIDATION LOOP ---\n",
    "num_epochs = 5\n",
    "print(f\"Starting fine-tuning for {num_epochs} epochs...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'\\nEpoch {epoch + 1}/{num_epochs}\\n----------------------------')\n",
    "    # =======================================\n",
    "    #               TRAINING\n",
    "    # =======================================\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"[Training]\"):\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # The model automatically calculates loss when labels are provided\n",
    "        outputs = model(**inputs, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_train_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    \n",
    "    # =======================================\n",
    "    #              VALIDATION\n",
    "    # =======================================\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    epoch_predictions = []\n",
    "    epoch_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(val_loader, desc=f\"[Validation]\"):\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Get model predictions (logits)\n",
    "            outputs = model(**inputs)\n",
    "            predictions = outputs.logits\n",
    "            \n",
    "            # Calculate validation loss manually\n",
    "            total_val_loss += loss_function(predictions.squeeze(), labels).item()\n",
    "            \n",
    "            # Collect predictions and labels for Spearman correlation\n",
    "            epoch_predictions.append(predictions.cpu())\n",
    "            epoch_labels.append(labels.cpu())\n",
    "    \n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    \n",
    "    # Calculate Spearman Correlation\n",
    "    all_predictions = torch.cat(epoch_predictions).numpy().flatten()\n",
    "    all_labels = torch.cat(epoch_labels).numpy().flatten()\n",
    "    spearman_corr, p_value = spearmanr(all_predictions, all_labels)\n",
    "    \n",
    "    print(f\"Training Loss: {avg_train_loss:.4f} | Validation Loss: {avg_val_loss:.4f} | Spearman Correlation: {spearman_corr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9083d6",
   "metadata": {},
   "source": [
    "## Baseline 4: Using ESMDance only as a feature extractor\n",
    "For another comparison to approach one, I'm using just ESMDance predictions as a feature extractor. Essentially using predicted molecular dynamics features. I should revisit this, as pooling these features for the binding head makes zero sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1d94a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Performing dry run to determine feature vector size...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t12_35M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determined concatenated feature vector size: 530\n",
      "Initializing base ESMDance model with original 50/13 heads...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t12_35M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading original weights from pretrained_weights/esmdance_update_60000.pt...\n",
      "Initializing trainable binding head with input size 530...\n",
      "Total trainable parameters: 140,981\n",
      "Starting fine-tuning for 5 epochs...\n",
      "\n",
      "Epoch 1/5\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 223/223 [00:16<00:00, 13.33it/s]\n",
      "[Validation]: 100%|██████████| 25/25 [00:02<00:00, 12.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1982 | Validation Loss: 0.1783 | Spearman Correlation: 0.5279\n",
      "\n",
      "Epoch 2/5\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 223/223 [00:19<00:00, 11.23it/s]\n",
      "[Validation]: 100%|██████████| 25/25 [00:02<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1818 | Validation Loss: 0.1612 | Spearman Correlation: 0.5305\n",
      "\n",
      "Epoch 3/5\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 223/223 [00:16<00:00, 13.38it/s]\n",
      "[Validation]: 100%|██████████| 25/25 [00:02<00:00, 10.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1690 | Validation Loss: 0.1480 | Spearman Correlation: 0.5356\n",
      "\n",
      "Epoch 4/5\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 223/223 [00:16<00:00, 13.49it/s]\n",
      "[Validation]: 100%|██████████| 25/25 [00:01<00:00, 12.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1571 | Validation Loss: 0.1409 | Spearman Correlation: 0.5436\n",
      "\n",
      "Epoch 5/5\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 223/223 [00:19<00:00, 11.61it/s]\n",
      "[Validation]: 100%|██████████| 25/25 [00:02<00:00, 11.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1514 | Validation Loss: 0.1326 | Spearman Correlation: 0.5535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import spearmanr\n",
    "import importlib.util\n",
    "\n",
    "# --- Import the base model class ---\n",
    "from scripts.esmdance_base_model import ESMwrap\n",
    "from scripts.base_config import config as base_config\n",
    "\n",
    "class ESMDanceForBinding(nn.Module):\n",
    "    \"\"\"\n",
    "    A wrapper model that uses the pre-trained ESMDance as a frozen feature extractor\n",
    "    and adds a new, trainable regression head on top.\n",
    "    \"\"\"\n",
    "    def __init__(self, config, feature_vector_size: int):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        print(\"Initializing base ESMDance model with original 50/13 heads...\")\n",
    "        self.esmdance_base = ESMwrap(esm2_select='model_35M', model_select='esmdance')\n",
    "        \n",
    "        original_weights_path = 'pretrained_weights/esmdance_update_60000.pt'\n",
    "        print(f\"Loading original weights from {original_weights_path}...\")\n",
    "        self.esmdance_base.load_state_dict(torch.load(original_weights_path, map_location='cpu'))\n",
    "\n",
    "        # Freeze all parameters of the base model\n",
    "        for param in self.esmdance_base.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Initialize binding head\n",
    "        print(f\"Initializing trainable binding head with input size {feature_vector_size}...\")\n",
    "        self.binding_head = nn.Sequential(\n",
    "            nn.Linear(feature_vector_size, feature_vector_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(feature_vector_size // 2, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        # The forward pass now just needs to extract features and pass to the head\n",
    "        with torch.no_grad():\n",
    "            # Get predictions and embeddings from the frozen base\n",
    "            base_preds = self.esmdance_base(inputs)\n",
    "            raw_embeddings = self.esmdance_base.esm2(**inputs).last_hidden_state\n",
    "            \n",
    "            # Pooling logic (this can be a helper method if you prefer)\n",
    "            attention_mask = inputs['attention_mask'].unsqueeze(-1)\n",
    "            pooled_embed = (raw_embeddings * attention_mask).sum(1) / attention_mask.sum(1)\n",
    "            \n",
    "            res_keys = self.config['training']['res_feature_idx'].keys()\n",
    "            tensors_to_cat = []\n",
    "            for k in res_keys:\n",
    "                tensor = base_preds[k]\n",
    "                if tensor.dim() == 2:\n",
    "                    tensors_to_cat.append(tensor.unsqueeze(-1))\n",
    "                else:\n",
    "                    tensors_to_cat.append(tensor)\n",
    "            res_features = torch.cat(tensors_to_cat, dim=-1)\n",
    "            pooled_res_features = (res_features * attention_mask).sum(1) / attention_mask.sum(1)\n",
    "            \n",
    "            feature_vector = torch.cat([pooled_embed, pooled_res_features], dim=-1)\n",
    "        \n",
    "        # Pass the extracted features through the trainable head\n",
    "        return self.binding_head(feature_vector)\n",
    "\n",
    "# --- SETUP ---\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- MODEL INITIALIZATION ---\n",
    "# 1. Perform a \"dry run\" with the base model to get the feature size\n",
    "print(\"Performing dry run to determine feature vector size...\")\n",
    "temp_base_model = ESMwrap(esm2_select='model_35M', model_select='esmdance').to(device)\n",
    "temp_base_model.eval()\n",
    "with torch.no_grad():\n",
    "    dummy_inputs, _ = next(iter(train_loader))\n",
    "    dummy_inputs = {k: v.to(device) for k, v in dummy_inputs.items()}\n",
    "    \n",
    "    # Manually run the feature extraction logic once\n",
    "    base_preds = temp_base_model(dummy_inputs)\n",
    "    raw_embeddings = temp_base_model.esm2(**dummy_inputs).last_hidden_state\n",
    "    attention_mask = dummy_inputs['attention_mask'].unsqueeze(-1)\n",
    "    pooled_embed = (raw_embeddings * attention_mask).sum(1) / attention_mask.sum(1)\n",
    "    res_keys = base_config['training']['res_feature_idx'].keys()\n",
    "    tensors_to_cat = [base_preds[k].unsqueeze(-1) if base_preds[k].dim() == 2 else base_preds[k] for k in res_keys]\n",
    "    res_features = torch.cat(tensors_to_cat, dim=-1)\n",
    "    pooled_res_features = (res_features * attention_mask).sum(1) / attention_mask.sum(1)\n",
    "    feature_vector = torch.cat([pooled_embed, pooled_res_features], dim=-1)\n",
    "    feature_vector_size = feature_vector.shape[1]\n",
    "    \n",
    "    del temp_base_model # Free up memory\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"Determined concatenated feature vector size: {feature_vector_size}\")\n",
    "\n",
    "# Now we can initialize the final model with the correct size\n",
    "model = ESMDanceForBinding(config=base_config, feature_vector_size=feature_vector_size).to(device)\n",
    "\n",
    "# --- LOSS AND OPTIMIZER ---\n",
    "loss_function = nn.MSELoss()\n",
    "# Pass the parameters of the new binding_head to the optimizer\n",
    "optimizer = AdamW(model.binding_head.parameters(), lr=1e-4)\n",
    "\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# --- TRAINING & VALIDATION LOOP ---\n",
    "num_epochs = 5\n",
    "print(f\"Starting fine-tuning for {num_epochs} epochs...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'\\nEpoch {epoch + 1}/{num_epochs}\\n----------------------------')\n",
    "    # =======================================\n",
    "    #               TRAINING\n",
    "    # =======================================\n",
    "    model.train() # Set the binding head to training mode (activates dropout)\n",
    "    total_train_loss = 0\n",
    "    \n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"[Training]\"):\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        labels = labels.to(device).unsqueeze(1) # Reshape labels for MSELoss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(inputs)\n",
    "        \n",
    "        loss = loss_function(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_train_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    \n",
    "    # =======================================\n",
    "    #              VALIDATION\n",
    "    # =======================================\n",
    "    model.eval() # Set the binding head to evaluation mode (disables dropout)\n",
    "    total_val_loss = 0\n",
    "    epoch_predictions = []\n",
    "    epoch_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(val_loader, desc=f\"[Validation]\"):\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            labels = labels.to(device).unsqueeze(1)\n",
    "            \n",
    "            predictions = model(inputs)\n",
    "            \n",
    "            total_val_loss += loss_function(predictions, labels).item()\n",
    "\n",
    "            # Collect predictions and labels for Spearman correlation\n",
    "            epoch_predictions.append(predictions.cpu().detach())\n",
    "            epoch_labels.append(labels.cpu().detach())\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "    # Calculate Spearman Correlation\n",
    "    all_predictions = torch.cat(epoch_predictions).numpy().flatten()\n",
    "    all_labels = torch.cat(epoch_labels).numpy().flatten()\n",
    "    spearman_corr, p_value = spearmanr(all_predictions, all_labels)\n",
    "    \n",
    "    print(f\"Training Loss: {avg_train_loss:.4f} | Validation Loss: {avg_val_loss:.4f} | Spearman Correlation: {spearman_corr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2bfe8c",
   "metadata": {},
   "source": [
    "## Baseline 5: ESMDance with Extra Layers Unfrozen\n",
    "This model unfreezes all of the layers added by ESMDance to ESM2, as well the final two layers of ESM2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7766325f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Performing dry run to determine feature vector size...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t12_35M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determined concatenated feature vector size: 530\n",
      "Initializing base ESMDance model with original 50/13 heads...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t12_35M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading original weights from pretrained_weights/esmdance_update_60000.pt...\n",
      "Initializing trainable binding head with input size 530...\n",
      "Total trainable parameters: 6,869,444\n",
      "Starting fine-tuning for 5 epochs...\n",
      "\n",
      "Epoch 1/5\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 223/223 [00:13<00:00, 17.09it/s]\n",
      "[Validation]: 100%|██████████| 25/25 [00:01<00:00, 17.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1982 | Validation Loss: 0.1783 | Spearman Correlation: 0.5279\n",
      "\n",
      "Epoch 2/5\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 223/223 [00:10<00:00, 20.95it/s] \n",
      "[Validation]: 100%|██████████| 25/25 [00:01<00:00, 17.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1818 | Validation Loss: 0.1612 | Spearman Correlation: 0.5305\n",
      "\n",
      "Epoch 3/5\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 223/223 [00:13<00:00, 16.87it/s]\n",
      "[Validation]: 100%|██████████| 25/25 [00:01<00:00, 17.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1690 | Validation Loss: 0.1480 | Spearman Correlation: 0.5356\n",
      "\n",
      "Epoch 4/5\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 223/223 [00:10<00:00, 21.00it/s] \n",
      "[Validation]: 100%|██████████| 25/25 [00:01<00:00, 17.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1571 | Validation Loss: 0.1409 | Spearman Correlation: 0.5436\n",
      "\n",
      "Epoch 5/5\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 223/223 [00:13<00:00, 17.01it/s]\n",
      "[Validation]: 100%|██████████| 25/25 [00:01<00:00, 17.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1514 | Validation Loss: 0.1326 | Spearman Correlation: 0.5535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import spearmanr\n",
    "import importlib.util\n",
    "\n",
    "# --- Import the base model class ---\n",
    "from scripts.esmdance_base_model import ESMwrap\n",
    "from scripts.base_config import config as base_config\n",
    "\n",
    "class ESMDanceForBinding(nn.Module):\n",
    "    \"\"\"\n",
    "    A wrapper model that uses the pre-trained ESMDance as a frozen feature extractor\n",
    "    and adds a new, trainable regression head on top.\n",
    "    \"\"\"\n",
    "    def __init__(self, config, feature_vector_size: int):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        print(\"Initializing base ESMDance model with original 50/13 heads...\")\n",
    "        self.esmdance_base = ESMwrap(esm2_select='model_35M', model_select='esmdance')\n",
    "        \n",
    "        original_weights_path = 'pretrained_weights/esmdance_update_60000.pt'\n",
    "        print(f\"Loading original weights from {original_weights_path}...\")\n",
    "        self.esmdance_base.load_state_dict(torch.load(original_weights_path, map_location='cpu'))\n",
    "\n",
    "        # Freeze all parameters of the base model\n",
    "        for param in self.esmdance_base.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Unfreeze final layers of ESMDance\n",
    "        for param in self.esmdance_base.res_pred_nn.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        for param in self.esmdance_base.res_transform_nn.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        for param in self.esmdance_base.pair_middle_linear.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        for param in self.esmdance_base.pair_pred_linear.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        # Unfreeze final layers of ESM2\n",
    "        num_layers_to_unfreeze = 2\n",
    "        for layer in self.esmdance_base.esm2.encoder.layer[-num_layers_to_unfreeze:]:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = True\n",
    "        \n",
    "        # Initialize the binding head\n",
    "        print(f\"Initializing trainable binding head with input size {feature_vector_size}...\")\n",
    "        self.binding_head = nn.Sequential(\n",
    "            nn.Linear(feature_vector_size, feature_vector_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(feature_vector_size // 2, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        # The forward pass now just needs to extract features and pass to the head\n",
    "        with torch.no_grad():\n",
    "            # Get predictions and embeddings from the frozen base\n",
    "            base_preds = self.esmdance_base(inputs)\n",
    "            raw_embeddings = self.esmdance_base.esm2(**inputs).last_hidden_state\n",
    "            \n",
    "            # Pooling logic (this can be a helper method if you prefer)\n",
    "            attention_mask = inputs['attention_mask'].unsqueeze(-1)\n",
    "            pooled_embed = (raw_embeddings * attention_mask).sum(1) / attention_mask.sum(1)\n",
    "            \n",
    "            res_keys = self.config['training']['res_feature_idx'].keys()\n",
    "            tensors_to_cat = []\n",
    "            for k in res_keys:\n",
    "                tensor = base_preds[k]\n",
    "                if tensor.dim() == 2:\n",
    "                    tensors_to_cat.append(tensor.unsqueeze(-1))\n",
    "                else:\n",
    "                    tensors_to_cat.append(tensor)\n",
    "            res_features = torch.cat(tensors_to_cat, dim=-1)\n",
    "            pooled_res_features = (res_features * attention_mask).sum(1) / attention_mask.sum(1)\n",
    "            \n",
    "            feature_vector = torch.cat([pooled_embed, pooled_res_features], dim=-1)\n",
    "        \n",
    "        # Pass the extracted features through the trainable head\n",
    "        return self.binding_head(feature_vector)\n",
    "\n",
    "# =============================================================================\n",
    "#                            MAIN TRAINING SCRIPT\n",
    "# =============================================================================\n",
    "\n",
    "# --- SETUP ---\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- MODEL INITIALIZATION ---\n",
    "# 1. Perform a \"dry run\" with the base model to get the feature size\n",
    "print(\"Performing dry run to determine feature vector size...\")\n",
    "temp_base_model = ESMwrap(esm2_select='model_35M', model_select='esmdance').to(device)\n",
    "temp_base_model.eval()\n",
    "with torch.no_grad():\n",
    "    dummy_inputs, _ = next(iter(train_loader))\n",
    "    dummy_inputs = {k: v.to(device) for k, v in dummy_inputs.items()}\n",
    "    \n",
    "    # Manually run the feature extraction logic once\n",
    "    base_preds = temp_base_model(dummy_inputs)\n",
    "    raw_embeddings = temp_base_model.esm2(**dummy_inputs).last_hidden_state\n",
    "    attention_mask = dummy_inputs['attention_mask'].unsqueeze(-1)\n",
    "    pooled_embed = (raw_embeddings * attention_mask).sum(1) / attention_mask.sum(1)\n",
    "    res_keys = base_config['training']['res_feature_idx'].keys()\n",
    "    tensors_to_cat = [base_preds[k].unsqueeze(-1) if base_preds[k].dim() == 2 else base_preds[k] for k in res_keys]\n",
    "    res_features = torch.cat(tensors_to_cat, dim=-1)\n",
    "    pooled_res_features = (res_features * attention_mask).sum(1) / attention_mask.sum(1)\n",
    "    feature_vector = torch.cat([pooled_embed, pooled_res_features], dim=-1)\n",
    "    feature_vector_size = feature_vector.shape[1]\n",
    "    \n",
    "    del temp_base_model # Free up memory\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"Determined concatenated feature vector size: {feature_vector_size}\")\n",
    "\n",
    "# Initialize the final model with the correct size\n",
    "model = ESMDanceForBinding(config=base_config, feature_vector_size=feature_vector_size).to(device)\n",
    "\n",
    "# --- LOSS AND OPTIMIZER ---\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# --- TRAINING & VALIDATION LOOP ---\n",
    "num_epochs = 5\n",
    "print(f\"Starting fine-tuning for {num_epochs} epochs...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'\\nEpoch {epoch + 1}/{num_epochs}\\n----------------------------')\n",
    "    # =======================================\n",
    "    #               TRAINING\n",
    "    # =======================================\n",
    "    model.train() # Set the binding head to training mode (activates dropout)\n",
    "    total_train_loss = 0\n",
    "    \n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"[Training]\"):\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        labels = labels.to(device).unsqueeze(1) # Reshape labels for MSELoss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(inputs)\n",
    "        \n",
    "        loss = loss_function(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_train_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    \n",
    "    # =======================================\n",
    "    #              VALIDATION\n",
    "    # =======================================\n",
    "    model.eval() # Set the binding head to evaluation mode (disables dropout)\n",
    "    total_val_loss = 0\n",
    "    epoch_predictions = []\n",
    "    epoch_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(val_loader, desc=f\"[Validation]\"):\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            labels = labels.to(device).unsqueeze(1)\n",
    "            \n",
    "            predictions = model(inputs)\n",
    "            \n",
    "            total_val_loss += loss_function(predictions, labels).item()\n",
    "\n",
    "            # Collect predictions and labels for Spearman correlation\n",
    "            epoch_predictions.append(predictions.cpu().detach())\n",
    "            epoch_labels.append(labels.cpu().detach())\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "    # Calculate Spearman Correlation\n",
    "    all_predictions = torch.cat(epoch_predictions).numpy().flatten()\n",
    "    all_labels = torch.cat(epoch_labels).numpy().flatten()\n",
    "    spearman_corr, p_value = spearmanr(all_predictions, all_labels)\n",
    "    \n",
    "    print(f\"Training Loss: {avg_train_loss:.4f} | Validation Loss: {avg_val_loss:.4f} | Spearman Correlation: {spearman_corr:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdf3fd4",
   "metadata": {},
   "source": [
    "## Baseline 6: Trainable ESMDance with no pooling\n",
    "This model changes the binding head to an attention head to process all of the information from ESMDance. It also unfreezes all parameters through the model from the end to the two final layers of ESM2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0366373f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Initializing base ESMDance model with original 50/13 heads...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t12_35M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading original weights from pretrained_weights/esmdance_update_60000.pt...\n",
      "Initializing trainable binding head...\n",
      "Total trainable parameters: 10,247,384\n",
      "Starting fine-tuning for 5 epochs...\n",
      "\n",
      "Epoch 1/5\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 223/223 [00:20<00:00, 10.81it/s]\n",
      "[Validation]: 100%|██████████| 25/25 [00:01<00:00, 15.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2024 | Validation Loss: 0.1537 | Spearman Correlation: 0.5905\n",
      "\n",
      "Epoch 2/5\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 223/223 [00:20<00:00, 10.92it/s]\n",
      "[Validation]: 100%|██████████| 25/25 [00:01<00:00, 15.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1299 | Validation Loss: 0.1152 | Spearman Correlation: 0.6771\n",
      "\n",
      "Epoch 3/5\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 223/223 [00:20<00:00, 10.74it/s]\n",
      "[Validation]: 100%|██████████| 25/25 [00:01<00:00, 15.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1082 | Validation Loss: 0.1074 | Spearman Correlation: 0.7111\n",
      "\n",
      "Epoch 4/5\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 223/223 [00:23<00:00,  9.54it/s]\n",
      "[Validation]: 100%|██████████| 25/25 [00:01<00:00, 15.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0992 | Validation Loss: 0.1002 | Spearman Correlation: 0.7402\n",
      "\n",
      "Epoch 5/5\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 223/223 [00:20<00:00, 10.86it/s]\n",
      "[Validation]: 100%|██████████| 25/25 [00:01<00:00, 15.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0990 | Validation Loss: 0.0957 | Spearman Correlation: 0.7465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import spearmanr\n",
    "import importlib.util\n",
    "\n",
    "# --- Import the base model class ---\n",
    "from scripts.esmdance_base_model import ESMwrap\n",
    "from scripts.base_config import config as base_config\n",
    "\n",
    "class AttentionBindingHead(nn.Module):\n",
    "    \"\"\"\n",
    "    A binding head that processes per-residue and per-pair features using a biased attention mechanism.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim, pair_dim, num_heads=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        # A small MLP to process the pairwise features into an attention bias\n",
    "        self.pair_bias_net = nn.Sequential(\n",
    "            nn.Linear(pair_dim, num_heads),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_heads, num_heads)\n",
    "        )\n",
    "        \n",
    "        # A standard multi-head self-attention layer\n",
    "        self.attention = nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
    "        self.layer_norm1 = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        # Final feed-forward network\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embed_dim*4, embed_dim)\n",
    "        )\n",
    "        self.layer_norm2 = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        # Final regression head that acts on the [CLS] token embedding\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\\\n",
    "            nn.Linear(embed_dim // 2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, residue_features, pair_features, attention_mask):\n",
    "        # residue_features: [batch, seq_len, embed_dim]\n",
    "        # pair_features:    [batch, seq_len, seq_len, pair_dim]\n",
    "        # attention_mask:   [batch, seq_len]\n",
    "\n",
    "        # Create the attention bias from pairwise features\n",
    "        # Shape: [batch, seq_len, seq_len, num_heads] -> [batch * num_heads, seq_len, seq_len]\n",
    "        pair_bias = self.pair_bias_net(pair_features).permute(0, 3, 1, 2)\n",
    "        batch_size, num_heads, seq_len, _ = pair_bias.shape\n",
    "        pair_bias = pair_bias.reshape(batch_size * num_heads, seq_len, seq_len)\n",
    "\n",
    "        # Create the padding mask for the attention layer\n",
    "        # Shape: [batch, seq_len] -> [batch, 1, 1, seq_len] -> broadcast\n",
    "        padding_mask = (attention_mask == 0)\n",
    "\n",
    "        # Perform biased self-attention\n",
    "        attn_output, _ = self.attention(\n",
    "            residue_features, residue_features, residue_features,\n",
    "            key_padding_mask=padding_mask,\n",
    "            attn_mask=pair_bias\n",
    "        )\n",
    "        residue_features = self.layer_norm1(residue_features + attn_output)\n",
    "        \n",
    "        # Pass through the feed-forward network\n",
    "        ffn_output = self.ffn(residue_features)\n",
    "        residue_features = self.layer_norm2(residue_features + ffn_output)\n",
    "        \n",
    "        # Select the [CLS] token embedding (at index 0) for the final prediction\n",
    "        cls_token_embedding = residue_features[:, 0, :]\n",
    "        \n",
    "        return self.regressor(cls_token_embedding)\n",
    "\n",
    "class ESMDanceForBinding(nn.Module):\n",
    "    \"\"\"\n",
    "    A wrapper model that uses the pre-trained ESMDance as a frozen feature extractor\n",
    "    and adds a new, trainable regression head on top.\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        print(\"Initializing base ESMDance model with original 50/13 heads...\")\n",
    "        self.esmdance_base = ESMwrap(esm2_select='model_35M', model_select='esmdance')\n",
    "        \n",
    "        original_weights_path = 'pretrained_weights/esmdance_update_60000.pt'\n",
    "        print(f\"Loading original weights from {original_weights_path}...\")\n",
    "        self.esmdance_base.load_state_dict(torch.load(original_weights_path, map_location='cpu'))\n",
    "\n",
    "        # Freeze all parameters of the base model\n",
    "        for param in self.esmdance_base.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Unfreeze final layers of ESMDance\n",
    "        for param in self.esmdance_base.res_pred_nn.parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in self.esmdance_base.res_transform_nn.parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in self.esmdance_base.pair_middle_linear.parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in self.esmdance_base.pair_pred_linear.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        # Unfreeze final layers of ESM2\n",
    "        num_layers_to_unfreeze = 2\n",
    "        for layer in self.esmdance_base.esm2.encoder.layer[-num_layers_to_unfreeze:]:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = True\n",
    "        \n",
    "        # Initialize the binding head\n",
    "        print(f\"Initializing trainable binding head...\")\n",
    "        # Input to the head will be raw embeddings + predicted residue features\n",
    "        embed_dim = config['model_35M']['embed_dim']\n",
    "        res_out_dim = config['model_35M']['res_out_dim']\n",
    "        pair_out_dim = config['model_35M']['pair_out_dim']\n",
    "        \n",
    "        self.binding_head = AttentionBindingHead(\n",
    "            embed_dim=embed_dim + res_out_dim, # 480 + 50 = 530\n",
    "            pair_dim=pair_out_dim              # 13\n",
    "        )\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        # The forward pass is now trainable for some layers\n",
    "        base_outputs = self.esmdance_base(inputs)\n",
    "        raw_embeddings = self.esmdance_base.esm2(**inputs).last_hidden_state\n",
    "        \n",
    "        # --- Gather Features (No Pooling) ---\n",
    "        # 1. Gather residue features\n",
    "        res_keys = base_config['training']['res_feature_idx'].keys()\n",
    "        res_tensors = [base_outputs[k].unsqueeze(-1) if base_outputs[k].dim() == 2 else base_outputs[k] for k in res_keys]\n",
    "        predicted_res_features = torch.cat(res_tensors, dim=-1)\n",
    "        \n",
    "        # 2. Gather pairwise features\n",
    "        pair_keys = base_config['training']['pair_feature_idx'].keys()\n",
    "        predicted_pair_features = torch.stack([base_outputs[k] for k in pair_keys], dim=-1)\n",
    "        \n",
    "        # 3. Concatenate raw embeddings with predicted residue features\n",
    "        final_residue_features = torch.cat([raw_embeddings, predicted_res_features], dim=-1)\n",
    "        \n",
    "        # 4. Pass everything to the new binding head\n",
    "        return self.binding_head(\n",
    "            residue_features=final_residue_features,\n",
    "            pair_features=predicted_pair_features,\n",
    "            attention_mask=inputs['attention_mask']\n",
    "        )\n",
    "\n",
    "# =============================================================================\n",
    "#                            MAIN TRAINING SCRIPT\n",
    "# =============================================================================\n",
    "\n",
    "# --- SETUP ---\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- MODEL INITIALIZATION ---\n",
    "model = ESMDanceForBinding(config=base_config).to(device)\n",
    "\n",
    "# --- LOSS AND OPTIMIZER ---\n",
    "loss_function = nn.MSELoss()\n",
    "# The optimizer will now correctly find all trainable parameters\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5) # Use a smaller LR for fine-tuning\n",
    "\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# --- TRAINING & VALIDATION LOOP ---\n",
    "num_epochs = 5\n",
    "print(f\"Starting fine-tuning for {num_epochs} epochs...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'\\nEpoch {epoch + 1}/{num_epochs}\\n----------------------------')\n",
    "    # =======================================\n",
    "    #               TRAINING\n",
    "    # =======================================\n",
    "    model.train() # Set the binding head to training mode (activates dropout)\n",
    "    total_train_loss = 0\n",
    "    \n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"[Training]\"):\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        labels = labels.to(device).unsqueeze(1) # Reshape labels for MSELoss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(inputs)\n",
    "        \n",
    "        loss = loss_function(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_train_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    \n",
    "    # =======================================\n",
    "    #              VALIDATION\n",
    "    # =======================================\n",
    "    model.eval() # Set the binding head to evaluation mode (disables dropout)\n",
    "    total_val_loss = 0\n",
    "    epoch_predictions = []\n",
    "    epoch_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(val_loader, desc=f\"[Validation]\"):\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            labels = labels.to(device).unsqueeze(1)\n",
    "            \n",
    "            predictions = model(inputs)\n",
    "            \n",
    "            total_val_loss += loss_function(predictions, labels).item()\n",
    "\n",
    "            # Collect predictions and labels for Spearman correlation\n",
    "            epoch_predictions.append(predictions.cpu().detach())\n",
    "            epoch_labels.append(labels.cpu().detach())\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "    # Calculate Spearman Correlation\n",
    "    all_predictions = torch.cat(epoch_predictions).numpy().flatten()\n",
    "    all_labels = torch.cat(epoch_labels).numpy().flatten()\n",
    "    spearman_corr, p_value = spearmanr(all_predictions, all_labels)\n",
    "    \n",
    "    print(f\"Training Loss: {avg_train_loss:.4f} | Validation Loss: {avg_val_loss:.4f} | Spearman Correlation: {spearman_corr:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ce07d7",
   "metadata": {},
   "source": [
    "Just out of curiousity, how much of this is being aided by ESM2 layers being tunable? Below, I'll freeze them and see how it performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e50551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Initializing base ESMDance model with original 50/13 heads...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t12_35M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading original weights from pretrained_weights/esmdance_update_60000.pt...\n",
      "Initializing trainable binding head...\n",
      "Total trainable parameters: 4,705,304\n",
      "Starting fine-tuning for 5 epochs...\n",
      "\n",
      "Epoch 1/5\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 223/223 [00:18<00:00, 12.12it/s]\n",
      "[Validation]: 100%|██████████| 25/25 [00:01<00:00, 15.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2125 | Validation Loss: 0.1987 | Spearman Correlation: 0.4990\n",
      "\n",
      "Epoch 2/5\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 223/223 [00:17<00:00, 12.44it/s]\n",
      "[Validation]: 100%|██████████| 25/25 [00:01<00:00, 16.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1842 | Validation Loss: 0.1737 | Spearman Correlation: 0.5247\n",
      "\n",
      "Epoch 3/5\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 223/223 [00:20<00:00, 10.68it/s]\n",
      "[Validation]: 100%|██████████| 25/25 [-1:59:59<00:00, -21.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1403 | Validation Loss: 0.1424 | Spearman Correlation: 0.5836\n",
      "\n",
      "Epoch 4/5\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 223/223 [00:20<00:00, 10.71it/s]\n",
      "[Validation]: 100%|██████████| 25/25 [00:01<00:00, 15.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1307 | Validation Loss: 0.1361 | Spearman Correlation: 0.6150\n",
      "\n",
      "Epoch 5/5\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 223/223 [00:18<00:00, 12.31it/s]\n",
      "[Validation]: 100%|██████████| 25/25 [00:01<00:00, 15.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1210 | Validation Loss: 0.1242 | Spearman Correlation: 0.6408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import spearmanr\n",
    "import importlib.util\n",
    "\n",
    "# --- Import the base model class ---\n",
    "from scripts.esmdance_base_model import ESMwrap\n",
    "from scripts.base_config import config as base_config\n",
    "\n",
    "class AttentionBindingHead(nn.Module):\n",
    "    \"\"\"\n",
    "    A binding head that processes per-residue and per-pair features using a biased attention mechanism.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim, pair_dim, num_heads=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        # A small MLP to process the pairwise features into an attention bias\n",
    "        self.pair_bias_net = nn.Sequential(\n",
    "            nn.Linear(pair_dim, num_heads),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_heads, num_heads)\n",
    "        )\n",
    "        \n",
    "        # A standard multi-head self-attention layer\n",
    "        self.attention = nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
    "        self.layer_norm1 = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        # Final feed-forward network\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embed_dim*4, embed_dim)\n",
    "        )\n",
    "        self.layer_norm2 = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        # Final regression head that acts on the [CLS] token embedding\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\\\n",
    "            nn.Linear(embed_dim // 2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, residue_features, pair_features, attention_mask):\n",
    "        # residue_features: [batch, seq_len, embed_dim]\n",
    "        # pair_features:    [batch, seq_len, seq_len, pair_dim]\n",
    "        # attention_mask:   [batch, seq_len]\n",
    "\n",
    "        # Create the attention bias from pairwise features\n",
    "        # Shape: [batch, seq_len, seq_len, num_heads] -> [batch * num_heads, seq_len, seq_len]\n",
    "        pair_bias = self.pair_bias_net(pair_features).permute(0, 3, 1, 2)\n",
    "        batch_size, num_heads, seq_len, _ = pair_bias.shape\n",
    "        pair_bias = pair_bias.reshape(batch_size * num_heads, seq_len, seq_len)\n",
    "\n",
    "        # Create the padding mask for the attention layer\n",
    "        # Shape: [batch, seq_len] -> [batch, 1, 1, seq_len] -> broadcast\n",
    "        padding_mask = (attention_mask == 0)\n",
    "\n",
    "        # Perform biased self-attention\n",
    "        attn_output, _ = self.attention(\n",
    "            residue_features, residue_features, residue_features,\n",
    "            key_padding_mask=padding_mask,\n",
    "            attn_mask=pair_bias\n",
    "        )\n",
    "        residue_features = self.layer_norm1(residue_features + attn_output)\n",
    "        \n",
    "        # Pass through the feed-forward network\n",
    "        ffn_output = self.ffn(residue_features)\n",
    "        residue_features = self.layer_norm2(residue_features + ffn_output)\n",
    "        \n",
    "        # Select the [CLS] token embedding (at index 0) for the final prediction\n",
    "        cls_token_embedding = residue_features[:, 0, :]\n",
    "        \n",
    "        return self.regressor(cls_token_embedding)\n",
    "\n",
    "class ESMDanceForBinding(nn.Module):\n",
    "    \"\"\"\n",
    "    A wrapper model that uses the pre-trained ESMDance as a frozen feature extractor\n",
    "    and adds a new, trainable regression head on top.\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        print(\"Initializing base ESMDance model with original 50/13 heads...\")\n",
    "        self.esmdance_base = ESMwrap(esm2_select='model_35M', model_select='esmdance')\n",
    "        \n",
    "        original_weights_path = 'pretrained_weights/esmdance_update_60000.pt'\n",
    "        print(f\"Loading original weights from {original_weights_path}...\")\n",
    "        self.esmdance_base.load_state_dict(torch.load(original_weights_path, map_location='cpu'))\n",
    "\n",
    "        # Freeze all parameters of the base model\n",
    "        for param in self.esmdance_base.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Unfreeze final layers of ESMDance\n",
    "        for param in self.esmdance_base.res_pred_nn.parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in self.esmdance_base.res_transform_nn.parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in self.esmdance_base.pair_middle_linear.parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in self.esmdance_base.pair_pred_linear.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        ## Unfreeze final layers of ESM2\n",
    "        #num_layers_to_unfreeze = 2\n",
    "        #for layer in self.esmdance_base.esm2.encoder.layer[-num_layers_to_unfreeze:]:\n",
    "        #    for param in layer.parameters():\n",
    "        #        param.requires_grad = True\n",
    "        \n",
    "        # Initialize the binding head\n",
    "        print(f\"Initializing trainable binding head...\")\n",
    "        # Input to the head will be raw embeddings + predicted residue features\n",
    "        embed_dim = config['model_35M']['embed_dim']\n",
    "        res_out_dim = config['model_35M']['res_out_dim']\n",
    "        pair_out_dim = config['model_35M']['pair_out_dim']\n",
    "        \n",
    "        self.binding_head = AttentionBindingHead(\n",
    "            embed_dim=embed_dim + res_out_dim, # 480 + 50 = 530\n",
    "            pair_dim=pair_out_dim              # 13\n",
    "        )\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        # The forward pass is now trainable for some layers\n",
    "        base_outputs = self.esmdance_base(inputs)\n",
    "        raw_embeddings = self.esmdance_base.esm2(**inputs).last_hidden_state\n",
    "        \n",
    "        # --- Gather Features (No Pooling) ---\n",
    "        # 1. Gather residue features\n",
    "        res_keys = base_config['training']['res_feature_idx'].keys()\n",
    "        res_tensors = [base_outputs[k].unsqueeze(-1) if base_outputs[k].dim() == 2 else base_outputs[k] for k in res_keys]\n",
    "        predicted_res_features = torch.cat(res_tensors, dim=-1)\n",
    "        \n",
    "        # 2. Gather pairwise features\n",
    "        pair_keys = base_config['training']['pair_feature_idx'].keys()\n",
    "        predicted_pair_features = torch.stack([base_outputs[k] for k in pair_keys], dim=-1)\n",
    "        \n",
    "        # 3. Concatenate raw embeddings with predicted residue features\n",
    "        final_residue_features = torch.cat([raw_embeddings, predicted_res_features], dim=-1)\n",
    "        \n",
    "        # 4. Pass everything to the new binding head\n",
    "        return self.binding_head(\n",
    "            residue_features=final_residue_features,\n",
    "            pair_features=predicted_pair_features,\n",
    "            attention_mask=inputs['attention_mask']\n",
    "        )\n",
    "\n",
    "# =============================================================================\n",
    "#                            MAIN TRAINING SCRIPT\n",
    "# =============================================================================\n",
    "\n",
    "# --- SETUP ---\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- MODEL INITIALIZATION ---\n",
    "model = ESMDanceForBinding(config=base_config).to(device)\n",
    "\n",
    "# --- LOSS AND OPTIMIZER ---\n",
    "loss_function = nn.MSELoss()\n",
    "# The optimizer will now correctly find all trainable parameters\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5) # Use a smaller LR for fine-tuning\n",
    "\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# --- TRAINING & VALIDATION LOOP ---\n",
    "num_epochs = 5\n",
    "print(f\"Starting fine-tuning for {num_epochs} epochs...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'\\nEpoch {epoch + 1}/{num_epochs}\\n----------------------------')\n",
    "    # =======================================\n",
    "    #               TRAINING\n",
    "    # =======================================\n",
    "    model.train() # Set the binding head to training mode (activates dropout)\n",
    "    total_train_loss = 0\n",
    "    \n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"[Training]\"):\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        labels = labels.to(device).unsqueeze(1) # Reshape labels for MSELoss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(inputs)\n",
    "        \n",
    "        loss = loss_function(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_train_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    \n",
    "    # =======================================\n",
    "    #              VALIDATION\n",
    "    # =======================================\n",
    "    model.eval() # Set the binding head to evaluation mode (disables dropout)\n",
    "    total_val_loss = 0\n",
    "    epoch_predictions = []\n",
    "    epoch_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(val_loader, desc=f\"[Validation]\"):\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            labels = labels.to(device).unsqueeze(1)\n",
    "            \n",
    "            predictions = model(inputs)\n",
    "            \n",
    "            total_val_loss += loss_function(predictions, labels).item()\n",
    "\n",
    "            # Collect predictions and labels for Spearman correlation\n",
    "            epoch_predictions.append(predictions.cpu().detach())\n",
    "            epoch_labels.append(labels.cpu().detach())\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "    # Calculate Spearman Correlation\n",
    "    all_predictions = torch.cat(epoch_predictions).numpy().flatten()\n",
    "    all_labels = torch.cat(epoch_labels).numpy().flatten()\n",
    "    spearman_corr, p_value = spearmanr(all_predictions, all_labels)\n",
    "    \n",
    "    print(f\"Training Loss: {avg_train_loss:.4f} | Validation Loss: {avg_val_loss:.4f} | Spearman Correlation: {spearman_corr:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd9e033",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
